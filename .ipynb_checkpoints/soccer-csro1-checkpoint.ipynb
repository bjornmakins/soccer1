{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
      "     |███                             | 16.8 MB 16.6 MB/s eta 0:00:10\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-7rbj96cc because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data manipulation\\n\",\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\\n\",\n",
    "import numpy as np #  mathematical support for large, multi-dimensional arrays and matrices\\n\",\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import re\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "from matplotlib.patches import Arc\n",
    "import math\n",
    "#import xgboost\n",
    "#import dtreeviz\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Import up sound alert dependencies\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "## Insert whatever audio file you want above\n",
    "\n",
    "# allDone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('/kaggle/input/football-event-data')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('/group/interns202010/jmakins/Data')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('/Users/jordanmakins/Desktop/Data/Players')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jupyter-gpu-notebook-one-singularity.slm',\n",
       " 'README.md',\n",
       " 'slurm-245265.out',\n",
       " '.ipynb_checkpoints',\n",
       " 'soccer-csro1.ipynb',\n",
       " '.git',\n",
       " 'JordanMakins-PredAdaptiveSoccerAnalytics.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir('/group/interns202010/jmakins/Data/matches/')\n",
    "except:\n",
    "    pass\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/1228290092.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mEngland\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches_England.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mFrance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches_France.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mItaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches_Italy.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m             )\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir('/group/interns202010/jmakins/Data/matches/')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "England = pd.read_json('matches_England.json')\n",
    "France = pd.read_json('matches_France.json')\n",
    "Italy = pd.read_json('matches_Italy.json')\n",
    "Spain = pd.read_json('matches_Spain.json')\n",
    "Germany = pd.read_json('matches_Germany.json')\n",
    "\n",
    "England['Country'] = 'England'\n",
    "France['Country'] = 'France'\n",
    "Italy['Country'] = 'Italy'\n",
    "Spain['Country'] = 'Spain'\n",
    "Germany['Country'] = \"Germany\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    os.chdir('/group/interns202010/jmakins/Data')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "Teams = pd.read_json('teams.json')\n",
    "Players = pd.read_json('players.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('/group/interns202010/jmakins/Data/events')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.chdir('/Users/jordanmakins/Desktop/Data/events/')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events_France = pd.read_json('events_France.json')\n",
    "Events_Spain = pd.read_json('events_Spain.json')\n",
    "Events_Germany = pd.read_json('events_Germany.json')\n",
    "#Events_EuroChamps = pd.read_json('events_European_Championship.json')\n",
    "#Events_World_Cup = pd.read_json('events_World_Cup.json')\n",
    "Events_Italy = pd.read_json('events_Italy.json')\n",
    "Events_England = pd.read_json('events_England.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches = pd.concat([England, France, Italy, Spain, Germany], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches.drop(['duration'], inplace=True, axis =1) # removing groupName variable from World Cups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players.drop([\"passportArea\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players = Players.rename(columns ={'wyId': 'playerId'}) # rename for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = Teams.rename(columns = {'wyId': 'teamId'})\n",
    "Players = Players.rename(columns = {'currentTeamId': 'teamId'})\n",
    "Players = pd.merge(Players,Teams[['teamId', 'officialName']], on = 'teamId').rename(columns = {'officialName': 'clubName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players['Position'] = Players.role.apply(pd.Series)['code3'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players['birthCountry'] = Players.birthArea.apply(pd.Series)['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Players.drop([\"birthArea\", 'role'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Match Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match\n",
    "homeTeam, awayTeam = [],[]\n",
    "for x in teams:\n",
    "    homeTeam.append(x[0])\n",
    "    awayTeam.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for additional match statistics\n",
    "Matches[\"homeManagerId\"] = None\n",
    "for name in [\"Score\", \"ScoreHT\", \"ScoreET\", \"ScoreP\"]:\n",
    "    colname = \"home\" + name\n",
    "    colname2 = \"away\" + name\n",
    "    Matches[colname] = None\n",
    "    Matches[colname2] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse Home and Away teams as features from nest dictionary\n",
    "teams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match\n",
    "homeTeam, awayTeam = [],[]\n",
    "for game, team in enumerate(teams):\n",
    "    if Matches.teamsData[game:game+1][game][team[0]]['side'] == 'home':\n",
    "        homeTeam.append(team[0])\n",
    "        awayTeam.append(team[1])\n",
    "    else:\n",
    "        awayTeam.append(team[0])\n",
    "        homeTeam.append(team[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_stats(df, team): # function to parse team match stats from dictionary embedded in column teamsData from the Matches dataframe\n",
    "    \n",
    "    Bench, Starters, Manager, Score, ScoreHT, ScoreET, ScoreP, teamId = [],[],[],[],[],[],[],[]\n",
    "    \n",
    "    for game in range(0, len(df)):\n",
    "\n",
    "        Bench.append(list(pd.DataFrame.from_dict(df.teamsData[game][team[game]]['formation']['bench'])['playerId']))\n",
    "        Starters.append(list(pd.DataFrame.from_dict(df.teamsData[game][team[game]]['formation']['lineup'])['playerId']))\n",
    "        Manager.append(df.teamsData[game][team[game]]['coachId'])\n",
    "        Score.append(df.teamsData[game][team[game]]['score'])\n",
    "        ScoreHT.append(df.teamsData[game][team[game]]['scoreHT'])\n",
    "        ScoreET.append(df.teamsData[game][team[game]]['scoreET'])\n",
    "        ScoreP.append(df.teamsData[game][team[game]]['scoreP'])\n",
    "        teamId.append(df.teamsData[game][team[game]]['teamId'])\n",
    "    \n",
    "    return Bench, Starters, Manager, Score, ScoreHT, ScoreET, ScoreP, teamId\n",
    "\n",
    "homeBench, homeStarters, homeManager, homeScore, homeScoreHT, homeScoreET, homeScoreP, homeTeamId = get_team_stats(Matches, homeTeam)\n",
    "awayBench, awayStarters, awayManager, awayScore, awayScoreHT, awayScoreET, awayScoreP, awayTeamId = get_team_stats(Matches, awayTeam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating Bench Line Up Column Generation\n",
    "\n",
    "homeColNames = []\n",
    "for num in range(1,14): # add columns for home bench playerId\n",
    "     homeColNames.append(\"homeBenchPlayer\" + str(num))\n",
    "        \n",
    "awayColNames = []\n",
    "for num in range(1,14): # add columns for away bench playerId\n",
    "    awayColNames.append(\"awayBenchPlayer\" + str(num))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting bench counts as during errror handling reveals some matches had bench sizes of between 8 and 13 for certain fixtures\n",
    "import collections\n",
    "collections.Counter(list(map(lambda x: len(x), homeBench)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Bench Line Ups to DataFrame\n",
    "\n",
    "homeBench2 = pd.DataFrame(homeBench,\n",
    "     columns=homeColNames)\n",
    "awayBench2 = pd.DataFrame(awayBench,\n",
    "     columns=awayColNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating Starting Line Up Column Generation\n",
    "\n",
    "homeColNames =[]\n",
    "for num in range(1,12): # add columns for starting playerId\n",
    "     homeColNames.append(\"homePlayer\" + str(num))\n",
    "        \n",
    "awayColNames = []\n",
    "for num in range(1,12): # add columns for starting playerId\n",
    "    awayColNames.append(\"awayPlayer\" + str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining starting line ups, benches to matches dataframe\n",
    "\n",
    "homeStarters2 = pd.DataFrame(homeStarters,\n",
    "     columns=homeColNames)\n",
    "awayStarters2 = pd.DataFrame(awayStarters,\n",
    "     columns=awayColNames)\n",
    "\n",
    "Matches = Matches.join([homeStarters2, awayStarters2, homeBench2, awayBench2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add individual columns of match data\n",
    "Matches['homeManager'] = homeManager\n",
    "Matches['homeScore'] = homeScore\n",
    "Matches['homeScoreHT'] = homeScoreHT\n",
    "Matches['homeScoreET'] = homeScoreET\n",
    "Matches['homeScoreP'] = homeScoreP\n",
    "Matches['homeTeamId'] = homeTeamId\n",
    "Matches['awayManager'] = awayManager\n",
    "Matches['awayScore'] = awayScore\n",
    "Matches['awayScoreHT'] = awayScoreHT\n",
    "Matches['awayScoreET'] = awayScoreET\n",
    "Matches['awayScoreP'] = awayScoreP\n",
    "Matches['awayTeamId'] = awayTeamId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches.drop([\"teamsData\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Match Result as W, L or D for teams\n",
    "conditions = [\n",
    "    (Matches['winner'] == 0),\n",
    "    (Matches['winner'] == Matches['awayTeamId']),\n",
    "    (Matches['winner'] == Matches['homeTeamId'])\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0, -1, 1]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "Matches['Result'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches[\"date\"] = pd.to_datetime(Matches['dateutc']).dt.date # create a date column for Matches dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches[\"time\"] = pd.to_datetime(Matches['dateutc']).dt.time # create a time column for Matches dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prelim Dimensionality Reduction\n",
    "cols2Drop = ['status', 'roundId', 'gameweek', 'dateutc', 'label', 'referees', 'homeManagerId', 'seasonId']\n",
    "Matches.drop(cols2Drop, inplace=True, axis =1)\n",
    "Matches.drop(['winner', 'date', 'time'], inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches.rename(columns={'wyId':'matchId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches = Matches.fillna(0) # fill bench7players with Ids = 0 in order to prevent program crashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Manipulation for Match/Player Stats and then combine with existing Match(test) dataframe from aboves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decroos Github\n",
    "tags = [\n",
    "    (101, \"goal\"),\n",
    "    (102, \"own_goal\"),\n",
    "    (301, \"assist\"),\n",
    "    (302, \"key_pass\"),\n",
    "    (1901, \"counter_attack\"),\n",
    "    (401, \"left_foot\"),\n",
    "    (402, \"right_foot\"),\n",
    "    (403, \"head/body\"),\n",
    "    (1101, \"direct\"),\n",
    "    (1102, \"indirect\"),\n",
    "    (2001, \"dangerous_ball_lost\"),\n",
    "    (2101, \"blocked\"),\n",
    "    (801, \"high\"),\n",
    "    (802, \"low\"),\n",
    "    (1401, \"interception\"),\n",
    "    (1501, \"clearance\"),\n",
    "    (201, \"opportunity\"),\n",
    "    (1301, \"feint\"),\n",
    "    (1302, \"missed_ball\"),\n",
    "    (501, \"free_space_right\"),\n",
    "    (502, \"free_space_left\"),\n",
    "    (503, \"take_on_left\"),\n",
    "    (504, \"take_on_right\"),\n",
    "    (1601, \"sliding_tackle\"),\n",
    "    (601, \"anticipated\"),\n",
    "    (602, \"anticipation\"),\n",
    "    (1701, \"red_card\"),\n",
    "    (1702, \"yellow_card\"),\n",
    "    (1703, \"second_yellow_card\"),\n",
    "    (1201, \"position_goal_low_center\"),\n",
    "    (1202, \"position_goal_low_right\"),\n",
    "    (1203, \"position_goal_mid_center\"),\n",
    "    (1204, \"position_goal_mid_left\"),\n",
    "    (1205, \"position_goal_low_left\"),\n",
    "    (1206, \"position_goal_mid_right\"),\n",
    "    (1207, \"position_goal_high_center\"),\n",
    "    (1208, \"position_goal_high_left\"),\n",
    "    (1209, \"position_goal_high_right\"),\n",
    "    (1210, \"position_out_low_right\"),\n",
    "    (1211, \"position_out_mid_left\"),\n",
    "    (1212, \"position_out_low_left\"),\n",
    "    (1213, \"position_out_mid_right\"),\n",
    "    (1214, \"position_out_high_center\"),\n",
    "    (1215, \"position_out_high_left\"),\n",
    "    (1216, \"position_out_high_right\"),\n",
    "    (1217, \"position_post_low_right\"),\n",
    "    (1218, \"position_post_mid_left\"),\n",
    "    (1219, \"position_post_low_left\"),\n",
    "    (1220, \"position_post_mid_right\"),\n",
    "    (1221, \"position_post_high_center\"),\n",
    "    (1222, \"position_post_high_left\"),\n",
    "    (1223, \"position_post_high_right\"),\n",
    "    (901, \"through\"),\n",
    "    (1001, \"fairplay\"),\n",
    "    (701, \"lost\"),\n",
    "    (702, \"neutral\"),\n",
    "    (703, \"won\"),\n",
    "    (1801, \"accurate\"),\n",
    "    (1802, \"not_accurate\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = dict(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## I have kept this cell encase we need to impute integers for ML algorithms as oppose to strings\n",
    "# event_tag_ids = []\n",
    "# for ids in  list(trial[0:10]['tags']):\n",
    "#     event_tag_ids.append(list(map(lambda y: y['id'], ids)))\n",
    "# trial['event_tag_ids'] = event_tag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store event type tags ids in new column\n",
    "def event_tags(event_df):\n",
    "    event_tags = []\n",
    "    for ids in list(event_df['tags']):\n",
    "        event_tags.append(list(map(lambda y: tags[y['id']], ids)))\n",
    "\n",
    "    event_df['event_tags'] = event_tags\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunningTime(event_df):\n",
    "    # Solution to convert second half time into \n",
    "    secs_to_add = list(event_df[event_df['matchPeriod']==\"1H\"].groupby('matchId').tail(1)['eventSec'])\n",
    "    match_ids = list(event_df[\"matchId\"].unique())\n",
    "\n",
    "    for idx in range(0, len(match_ids)):\n",
    "        event_df['eventSec'] = list(np.where(\n",
    "           (event_df['matchId'] == match_ids[idx]) & (event_df['matchPeriod'] == \"2H\") , event_df['eventSec'] + secs_to_add[idx], event_df['eventSec']\n",
    "           ))\n",
    "    return event_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the result of the action\n",
    "def Result(event_df):\n",
    "    result = []\n",
    "    for tag in event_df[\"event_tags\"]:\n",
    "        if \"accurate\" in tag:\n",
    "            result.append(\"Accurate\")\n",
    "        elif \"not_accurate\" in tag:\n",
    "            result.append(\"Inaccurate\")\n",
    "        else:\n",
    "            result.append(\"\")\n",
    "    event_df[\"Result\"] = result \n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating description from success/failure of an action (event)\n",
    "def event_description(event_df):\n",
    "    subEventDescr = []\n",
    "    for tag in event_df[\"event_tags\"]:\n",
    "        descr = \" \".join(tag[:-1])\n",
    "        if descr != \"\":\n",
    "            subEventDescr.append(descr)\n",
    "        else:\n",
    "            subEventDescr.append(\"generic play\")\n",
    "    event_df[\"subEventDescription\"] = subEventDescr\n",
    "    event_df = event_df[(event_df[\"event_tags\"].str.len() != 0) & (event_df.subEventName != 'Ball out of the field')  & (event_df.subEventName != 'Goal kick')  ]\n",
    "    event_df = event_df[event_df[\"subEventName\"] != \"Throw in\"] # remove throw-ins as a relevant feature among successful teams for simpler analysis, unless its Rory Delap!\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separating description from success/failure of an action (event)\n",
    "# def event_description(event_df):\n",
    "#     subEventDescr = []\n",
    "#     for tag in event_df[\"event_tags\"]:\n",
    "#         descr = \" \".join(tag[:-1])\n",
    "#         if descr != \"\":\n",
    "#             subEventDescr.append(descr)\n",
    "#         else:\n",
    "#             subEventDescr.append(\"generic play\")\n",
    "#     event_df[\"subEventDescription\"] = subEventDescr\n",
    "#     event_df = event_df[(event_df[\"event_tags\"].str.len() != 0) & (event_df.subEventName != 'Ball out of the field')  & (event_df.subEventName != 'Goal kick') & (event_df.subEventName != 'Touch')   ]\n",
    "#     event_df = event_df[event_df[\"subEventName\"] != \"Throw in\"] # remove throw-ins as a relevant feature among successful teams for simpler analysis, unless its Rory Delap!\n",
    "#     return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Locations(event_df):\n",
    "\n",
    "    xStart,xEnd,yStart,yEnd = [], [], [], []\n",
    "    for pos in event_df[\"positions\"]:\n",
    "        if len(pos) == 2:\n",
    "            xStart.append(pos[0]['x'])\n",
    "            xEnd.append(pos[1]['x'])\n",
    "            yStart.append(pos[0]['y'])\n",
    "            yEnd.append(pos[1]['y'])\n",
    "        else:\n",
    "            xStart.append(pos[0]['x'])\n",
    "            xEnd.append(pos[0]['x'])\n",
    "            yStart.append(pos[0]['y'])\n",
    "            yEnd.append(pos[0]['y'])\n",
    "\n",
    "\n",
    "    event_df['xStart'], event_df['xEnd'], event_df['yStart'], event_df['yEnd'] = xStart, xEnd, yStart, yEnd\n",
    "    return event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform an event data frame\n",
    "def event_df_transform(event_df):\n",
    "    event_df = event_tags(event_df)\n",
    "    event_df = Result(event_df)\n",
    "    event_df = event_description(event_df)\n",
    "    event_df = Locations(event_df)\n",
    "    event_df.drop(['positions', \"event_tags\", \"tags\", \"eventName\"], inplace = True, axis = 1) #'id'\n",
    "    event_df = event_df[event_df.subEventName != \"\"]\n",
    "    event_df = event_df[event_df['playerId']!= 0]\n",
    "    event_df = RunningTime(event_df)\n",
    "    event_df['attackMetres'] = event_df['xEnd'] - event_df['xStart']\n",
    "    return event_df\n",
    "\n",
    "# stopped remove eventId\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform event_dfs\n",
    "\n",
    "Events_France = event_df_transform(Events_France)\n",
    "Events_Spain = event_df_transform(Events_Spain)\n",
    "Events_Germany = event_df_transform(Events_Germany)\n",
    "Events_Italy = event_df_transform(Events_Italy)\n",
    "Events_England = event_df_transform(Events_England)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zones(event_df, start_or_end):\n",
    "\n",
    "    conditions = [\n",
    "            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n",
    "            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <= 36))),\n",
    "            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 36)& (event_df['y'+ start_or_end] <= 64))),\n",
    "            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 64)& (event_df['y'+ start_or_end] <= 75))),\n",
    "            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n",
    "        \n",
    "            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 16.5) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <=  25))),\n",
    "            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 16.5) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n",
    "            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 16.5) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <=  75))),\n",
    "            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 16.5) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <=  100))),\n",
    "            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] >= 0))& (event_df['y'+ start_or_end] <=  25)),\n",
    "            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n",
    "            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <=  75))),\n",
    "            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <=  100))),\n",
    "            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n",
    "            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n",
    "            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <= 75))),\n",
    "            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n",
    "            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n",
    "            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <= 50))),\n",
    "            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <= 75))),\n",
    "            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n",
    "        \n",
    "            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] <= 25))),\n",
    "            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 25) & (event_df['y'+ start_or_end] <=  36))),\n",
    "            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 36) & (event_df['y'+ start_or_end] <= 64))),\n",
    "            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 64) & (event_df['y'+ start_or_end] <= 75))),\n",
    "            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 75) & (event_df['y'+ start_or_end] <= 100)))\n",
    "            ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "\n",
    "    # create a new column and us np.select to assign values to it using our lists as arguments\n",
    "    event_df['Zone'+ start_or_end] = np.select(conditions, values)\n",
    "    \n",
    "    return event_df\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_df in [Events_England, Events_Italy, Events_Spain, Events_France, Events_Germany]:\n",
    "    event_df = zones(event_df, \"Start\")\n",
    "    event_df = zones(event_df, \"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHange German row with 101\n",
    "Events_Germany.loc[Events_Germany.yEnd==101, ['yEnd']] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove events where playerId equals zero\n",
    "## There are two instances where goals are scored so we will handle these first and assign to correct players as these are important events\n",
    "# we can attempt to handle these into the real player sequences if we have time at the end of the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine average player coordinates on pitch across all possessions in a match\n",
    "def playerPosition(event_df):\n",
    "    df = event_df.groupby(['matchId','playerId']).agg({'xStart': ['mean'], 'yStart': ['mean']}).reset_index()\n",
    "    df.columns = [\"matchId\", \"playerId\", \"xStart\", \"yStart\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find positions for all players for big 5 Euro leagues\n",
    "a = playerPosition(Events_England)\n",
    "b = playerPosition(Events_France)\n",
    "c = playerPosition(Events_Italy)\n",
    "d = playerPosition(Events_Spain)\n",
    "e = playerPosition(Events_Germany)\n",
    "\n",
    "position_df = pd.concat([a,b,c,d,e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This dataframe is used relationally to fill correct team as events represent 2018 team, while player\n",
    "a = Events_England[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\n",
    "b = Events_France[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\n",
    "c = Events_Italy[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\n",
    "d = Events_Spain[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\n",
    "e = Events_Germany[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\n",
    "p_refs = pd.concat([a,b,c,d,e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create PA dataframe\n",
    "Player_Aggs = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\n",
    "\n",
    "# add ave field locations to players\n",
    "Player_Aggs = pd.merge(Player_Aggs, position_df, how = 'right', on= 'playerId').sort_values('matchId')\n",
    "Player_Aggs = pd.merge(Player_Aggs, p_refs, on = ['matchId', 'playerId'])\n",
    "Player_Aggs = pd.merge(Player_Aggs, Teams[['teamId', 'name']], on = 'teamId')\n",
    "Player_Aggs = pd.merge(Player_Aggs, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\n",
    "Player_Aggs.loc[Player_Aggs.teamId == Player_Aggs.homeTeamId, 'homeAway'] = \"home\"\n",
    "Player_Aggs.loc[Player_Aggs.teamId == Player_Aggs.awayTeamId, 'homeAway'] = \"away\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # #\n",
    "\n",
    "# var = \"Shot\"\n",
    "# varName = \"ShotsOnTarget\"\n",
    "\n",
    "# # this exists\n",
    "# df = Events_England.loc[(Events_England.Result == \"Accurate\" ) & (Events_England.subEventName== var )].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOnTarget')#.groupby([\"matchId\",'playerId']).agg(list).reset_index()\n",
    "# # [['playerId', 'matchId', \"ZoneStart\"]]\n",
    "# # # # # # # \n",
    "\n",
    "def transform_zonal(df, varName):\n",
    "\n",
    "    df = df.pivot_table(varName, ['playerId', 'matchId'], 'ZoneStart').fillna(0).reset_index()\n",
    "\n",
    "    column_indices = []\n",
    "    new_names = []\n",
    "    check_cols = list(range(1,27))\n",
    "    old_columns = list(df.columns[2:])\n",
    "\n",
    "    for num, col in enumerate(old_columns):\n",
    "        column_indices.append(num+2)\n",
    "        new_names.append(varName+ \"_ZoneS_\" + str(col))\n",
    "\n",
    "    # columns to be added \n",
    "    change_cols = np.setdiff1d(check_cols, old_columns) \n",
    "\n",
    "    old_names = df.columns[column_indices]\n",
    "    df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "\n",
    "    for col in change_cols:\n",
    "        df[varName + \"_ZoneS_\" + str(col)] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### unique entry dataframe for player gameTime at any point in a match by summarizing streams\n",
    "\n",
    "def playerGameTime(event_df):\n",
    "    df = event_df.groupby(['matchId','playerId'])['eventSec'].agg(['max', 'min']).reset_index()\n",
    "    df['gameTime (min)'] = round((df['max'] - df['min'])/60) # game time to the nearest minute\n",
    "    df.drop(['max', 'min'], inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "# derive gameTime per player and store in summary table\n",
    "a = playerGameTime(Events_England)\n",
    "b = playerGameTime(Events_France)\n",
    "c = playerGameTime(Events_Italy)\n",
    "d = playerGameTime(Events_Spain)\n",
    "e = playerGameTime(Events_Germany)\n",
    "\n",
    "playingTime = pd.concat([a,b,c,d,e]).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_goals(event_df):\n",
    "\n",
    "    # Create a column to recognize when a goal is scored\n",
    "    conditions = [\n",
    "        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Accurate\"))),\n",
    "        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Inaccurate\") & (event_df['subEventName'] == \"Shot\"))),\n",
    "        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Inaccurate\") & (event_df['subEventName'] != \"Shot\")))\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [1, 1, -1]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    event_df['Goal_Value'] = np.select(conditions, values, default = 0)\n",
    "    #[['playerId', 'matchId', \"ZoneStart\"]].groupby(['playerId', 'matchId', \"ZoneStart\"])\n",
    "    return event_df.groupby(['playerId', 'matchId', \"ZoneStart\"]).sum().reset_index()#[['playerId', 'matchId', 'Goal_Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in [Events_England, Events_Italy, Events_France, Events_Germany, Events_Spain]:\n",
    "    event = find_goals(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs = pd.merge(Player_Aggs, playingTime, how = 'left', on = ['playerId', 'matchId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function for event_df parsing\n",
    "def parseEvent_df(func, new_feature):\n",
    "    \n",
    "    aa = func(Events_England)\n",
    "    aa = transform_zonal(aa, new_feature)\n",
    "#     aa = aa.rename_axis(None, axis=1)\n",
    "    bb = func(Events_France)\n",
    "    bb = transform_zonal(bb, new_feature)\n",
    "#     bb = bb.rename_axis(None, axis=1)\n",
    "    cc = func(Events_Italy)\n",
    "    cc = transform_zonal(cc, new_feature)\n",
    "#     cc = cc.rename_axis(None, axis=1)\n",
    "    dd = func(Events_Spain)\n",
    "    dd = transform_zonal(dd, new_feature)\n",
    "#     dd = dd.rename_axis(None, axis=1)\n",
    "    ee = func(Events_Germany)\n",
    "    ee = transform_zonal(ee, new_feature)\n",
    "#     ee = ee.rename_axis(None, axis=1)\n",
    "    \n",
    "    return pd.concat([aa,bb,cc,dd,ee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for adding new feature column to Player_Aggs df\n",
    "def alter_Player_Aggs(new_feature_function, new_feature, PA_df):\n",
    "    \n",
    "    if \"Acc\" in new_feature:\n",
    "        df = parseEvent_df(new_feature_function, new_feature)\n",
    "        #df = transform_zonal(df, new_feature)\n",
    "        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n",
    "#         new_cols = [col for col in df if col.startswith(new_feature)]\n",
    "#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n",
    "        \n",
    "    elif 'acc' in new_feature:\n",
    "        df = parseEvent_df(new_feature_function, new_feature)\n",
    "        #df = transform_zonal(df, new_feature)\n",
    "        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n",
    "#         new_cols = [col for col in df if col.startswith(new_feature)]\n",
    "#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n",
    "        \n",
    "    else:\n",
    "        df = parseEvent_df(new_feature_function, new_feature)\n",
    "        #df = transform_zonal(df, new_feature)\n",
    "        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n",
    "#         new_cols = [col for col in df if col.startswith(new_feature)]\n",
    "#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n",
    "        \n",
    "#         PA_df[new_cols] = (PA_df[new_cols] / PA_df['gameTime (min)']) * 90 # get standardized stat index for 90mins\n",
    "    PA_df.iloc[:,15:] = PA_df.iloc[:,15:].fillna(0)\n",
    "    return PA_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# while datetime.datetime.now().hour < 17:\n",
    "#     x = 1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc angle to goal from any location in radians\n",
    "\n",
    "def angleToGoal(event_df):\n",
    "    \n",
    "    event_df['C'] = 10 # length of goal\n",
    "    event_df['A'] = ((100-event_df.xStart)**2+abs(45-event_df.yStart)**2)**.5\n",
    "    event_df['B'] = ((100-event_df.xStart)**2+abs(55-event_df.yStart)**2)**.5\n",
    "    event_df['angle_to_goal'] = (event_df['A'] * event_df['A'] + event_df['B'] * event_df['B'] - event_df['C'] * event_df['C'])/(2 * event_df['A'] * event_df['B'])\n",
    "    event_df['angle_to_goal'] = event_df['angle_to_goal'].apply(lambda row: round(math.radians(math.degrees(math.acos(row))),4))\n",
    "    # event_df['angle_to_goal'] = event_df['angle_to_goal'].apply(lambda row: round(math.degrees(row),2))\n",
    "    event_df.drop(['A', \"B\", \"C\"], inplace = True, axis=1)\n",
    "    return event_df\n",
    "        \n",
    "Events_England, Events_France = angleToGoal(Events_England), angleToGoal(Events_France)\n",
    "Events_Germany, Events_Spain = angleToGoal(Events_Germany), angleToGoal(Events_Spain)\n",
    "Events_Italy = angleToGoal(Events_Italy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to prepare dataframe for fdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result is event_df\n",
    "\n",
    "def player_goals(result):\n",
    "    \n",
    "    conditions = [\n",
    "            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Accurate\"))),\n",
    "            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Inaccurate\") & (result['subEventName'] == \"Shot\"))),\n",
    "            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Inaccurate\") & (result['subEventName'] != \"Shot\")))\n",
    "            ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [1, 1, -1]\n",
    "\n",
    "    # create a new column and us np.select to assign values to it using our lists as arguments\n",
    "    result['Goal_Value'] = np.select(conditions, values, default = 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_assists(event_df):\n",
    "    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerAssists')\n",
    "\n",
    "def corner_opportunity(event_df):\n",
    "    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('key_pass'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerOpportunitiesCreated')\n",
    "\n",
    "def corner_success(event_df):\n",
    "    return event_df[(event_df.subEventName==\"Corner\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulCorners')\n",
    "\n",
    "def corner_fail(event_df):\n",
    "    return event_df[(event_df.subEventName==\"Corner\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FailedCorners')\n",
    "\n",
    "def corner_assists(event_df):\n",
    "    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerAssists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attack Metres stat (how many forward metres achieved through events)\n",
    "def AccBackwardMetres(event_df):\n",
    "\n",
    "    df = event_df.loc[(event_df.Result == \"Accurate\" ) & (event_df.attackMetres < 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccBackMetres\"})\n",
    "    df[\"AccBackMetres\"] = df[\"AccBackMetres\"].abs()\n",
    "    return df\n",
    "\n",
    "def InaccBackwardMetres(event_df):\n",
    "\n",
    "    df = event_df.loc[(event_df.Result == \"Inaccurate\") & (event_df.attackMetres < 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccBackMetres\"})\n",
    "    df[\"InaccBackMetres\"] = df[\"InaccBackMetres\"].abs()\n",
    "    return df\n",
    "\n",
    "\n",
    "### Attack Metres stat (how many forward metres achieved through events)\n",
    "def AccForwardMetres(event_df):\n",
    "\n",
    "    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.attackMetres > 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccForwardMetres\"})\n",
    "    return df\n",
    "\n",
    "def InaccForwardMetres(event_df):\n",
    "\n",
    "    df = event_df.loc[(event_df.Result == \"Inaccurate\") & (event_df.attackMetres > 0 ) ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccForwardMetres\"})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# adding in total meterage of accurate and inaccurate movements by players in the vertical plane towards the goal\n",
    "# AccBackward = parseEvent_df(AccBackwardMetres)\n",
    "# InaccBackward = parseEvent_df(InaccBackwardMetres)\n",
    "# AccForward = parseEvent_df(AccForwardMetres)\n",
    "# InaccForward= parseEvent_df(InaccForwardMetres)\n",
    "\n",
    "# Player_Aggs = pd.merge(Player_Aggs, AccBackward, how= 'left', on =['playerId', 'matchId'])\n",
    "# Player_Aggs = pd.merge(Player_Aggs, InaccBackward, how = 'left', on =['playerId', 'matchId'])\n",
    "# Player_Aggs = pd.merge(Player_Aggs, AccForward, how= 'left', on =['playerId', 'matchId'])\n",
    "# Player_Aggs = pd.merge(Player_Aggs, InaccForward, how = 'left', on =['playerId', 'matchId'])\n",
    "# Player_Aggs.AccForwardMetres = Player_Aggs.AccForwardMetres.fillna(0)\n",
    "# Player_Aggs.InaccForwardMetres = Player_Aggs.InaccForwardMetres.fillna(0)-\n",
    "# Player_Aggs.AccBackMetres = Player_Aggs.AccBackMetres.fillna(0)\n",
    "# Player_Aggs.InaccBackMetres = Player_Aggs.InaccBackMetres.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events_England.subEventName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellanous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimulationFouls(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Simulation\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SimulationFouls')\n",
    "    return df\n",
    "\n",
    "def Fouls(event_df):\n",
    "    df= event_df[(event_df.subEventName.str.contains('foul'))| (event_df.subEventName.str.contains('Foul'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FoulsCommited')\n",
    "\n",
    "    return df\n",
    "\n",
    "def Clearances(event_df):\n",
    "    df =  event_df[(event_df.subEventName==\"Clearance\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Clearances')\n",
    "\n",
    "    return df\n",
    "    \n",
    "def AccLaunchMetres(event_df):\n",
    "    df =  event_df.loc[(event_df.Result == \"Accurate\") &(event_df.subEventName==\"Launch\")].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccLaunchMetres\"})\n",
    "\n",
    "    return df\n",
    "    \n",
    "def InaccLaunchMetres(event_df):\n",
    "    df = event_df.loc[(event_df.Result == \"Inaccurate\") &(event_df.subEventName==\"Launch\")].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccLaunchMetres\"})\n",
    "\n",
    "    return df\n",
    "\n",
    "def FreeKickCrossKey(event_df):\n",
    "    df = event_df[(event_df.subEventName == \"Free kick cross\")&(event_df.subEventDescription.str.contains(\"key\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FKKeyCross')\n",
    "\n",
    "    return df\n",
    "        \n",
    "def FreeKickCrossAssists(event_df):\n",
    "    df = event_df[(event_df.subEventName == \"Free kick cross\")&(event_df.subEventDescription.str.contains(\"assist\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FKCrossAssists')\n",
    "    return df\n",
    "    \n",
    "def FreeKickCrossAccuracy(event_df):\n",
    "    df1= event_df[(event_df.subEventName == \"Free kick cross\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickCrosses')\n",
    "    df2 = event_df[(event_df.subEventName == \"Free kick cross\")& (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccFreeKickCrosses')\n",
    "\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penaltiesConversion Statistic\n",
    "\n",
    "def PenaltiesConverted(event_df):\n",
    "    df1= event_df[(event_df.subEventName == \"Penalty\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltiesAttempted')\n",
    "\n",
    "    df2 = event_df[(event_df.subEventName == \"Penalty\")& (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltiesScored')\n",
    "\n",
    "    df1 = pd.merge(df1,df2, how='left', on = ['matchId', 'playerId'])\n",
    "    df1['PenaltiesScored'] = df1['PenaltiesScored'].fillna(0)\n",
    "    df1['penaltiesConversion'] = df1['PenaltiesScored'] / df1['PenaltiesAttempted']\n",
    "    df1.drop(['PenaltiesScored', 'PenaltiesAttempted' ], inplace=True, axis =1)\n",
    "\n",
    "\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Ground loose ball duel', 'Ground defending duel'\n",
    "def dangerousOpponentHalfRecoveries(event_df):\n",
    "    df = event_df[((event_df.subEventDescription.str.contains(\"won\")) | (event_df.subEventDescription.str.contains(\"interception\") & (event_df.Result==\"Accurate\"))) & (event_df.subEventName!=\"Ground attacking duel\") & (event_df.xEnd > 60)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousOpponentHalfRecoveries')\n",
    "    return df\n",
    "    \n",
    "def dangerousOwnHalfBallLost(event_df):\n",
    "    df = event_df[(event_df.Result==\"Inaccurate\") & (event_df.xEnd<40) & ((event_df.subEventName.str.contains(\"pass\")) | (event_df.subEventName.str.contains(\"Acceleration\")) | (event_df.subEventName.str.contains(\"Clearance\")) | ((event_df.subEventName.str.contains(\"duel\")) &(event_df.subEventName!='Ground defending duel')) | (event_df.subEventName.str.contains(\"Launch\")))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousOwnHalfBallLost')\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def dangerousDefDuelsLost(event_df):\n",
    "    df = event_df[(event_df.Result==\"Inaccurate\") & (event_df.xEnd<40) & (event_df.subEventName==\"Ground defending duel\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousDefDuelsLost')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step one proportion of low left shots saved\n",
    "\n",
    "possies = ['low_left', 'mid_left', 'high_left', 'low_center', 'mid_center', 'high_center', 'low_right', 'mid_right', 'high_right']\n",
    "\n",
    "def GoalKeepingZoneEfficiency(event_df, pos):\n",
    "    df1= event_df[((event_df.subEventName==\"Save attempt\") | (event_df.subEventName==\"Reflexes\")) &(event_df.subEventDescription.str.contains(pos))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='total_'+pos)\n",
    "\n",
    "    df2 = event_df[((event_df.subEventName==\"Save attempt\") | (event_df.subEventName==\"Reflexes\")) &(event_df.subEventDescription.str.contains(pos)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name=pos+'_saves')\n",
    "\n",
    "    df1 = pd.merge(df1,df2, how='left', on = ['matchId', 'playerId'])\n",
    "    df1[pos+'_saves'] = df1[pos+'_saves'].fillna(0)\n",
    "    df1[pos+'_save_efficiency'] = df1[pos+'_saves'] / df1['total_'+pos]\n",
    "    df1.drop([pos+'_saves', 'total_'+pos], inplace=True, axis =1)\n",
    "#     df1 = transform_zonal(df1, desiredName)\n",
    "    return df1\n",
    "\n",
    "\n",
    "# for pos in possies:\n",
    "#     a = GoalKeepingZoneEfficiency(Events_England, pos)\n",
    "#     b = GoalKeepingZoneEfficiency(Events_France, pos)\n",
    "#     c = GoalKeepingZoneEfficiency(Events_Italy, pos)\n",
    "#     d = GoalKeepingZoneEfficiency(Events_Spain, pos)\n",
    "#     e = GoalKeepingZoneEfficiency(Events_Germany, pos)\n",
    "#     df = pd.concat([a,b,c,d,e])\n",
    "#     Player_Aggs = pd.merge(Player_Aggs, df, how= 'left', on = ['playerId', 'matchId'])\n",
    "#     Player_Aggs[ pos + '_save_efficiency'] = Player_Aggs[pos + '_save_efficiency'].fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goals allowed\n",
    "def goalsAllowed(event_df):\n",
    "    df = event_df[((event_df.subEventName == \"Reflexes\")|(Events_England.subEventName == \"Save attempt\")) & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='goalsAllowed')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Successful save attempt\n",
    "def Saves(event_df):\n",
    "    df= event_df[((event_df.subEventName == \"Save attempt\")|(Events_England.subEventName == \"Save attempt\"))&(event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GkSaves')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Hand Pass\n",
    "def SuccessHandPass(event_df):\n",
    "    df= event_df[(event_df.subEventName == \"Hand pass\")&(event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateHandPass')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "# Inaccurate Hand Pass\n",
    "def FailedHandPass(event_df):\n",
    "    df = event_df[(event_df.subEventName == \"Hand pass\")&(event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateHandPass')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# GoalKeeper Leaving Line \n",
    "def LeavingLine(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Goalkeeper leaving line\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GKLeavingLineInstance')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crosses, Dribbles, Accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of succesful accelerations\n",
    "def SuccessAccelerations(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Acceleration') & (event_df.Result == 'Accurate')].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulAccels')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Number of failed accelerations\n",
    "def FailedAccelerations(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Acceleration') & (event_df.Result == 'Inaccurate')].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FailedAccels')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Total acceleration metres\n",
    "def AccelDistance(event_df):\n",
    "    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"CumAccelerationDist\"})\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accelerations into final third\n",
    "def AccelsIntoFinalThird(event_df):\n",
    "    df= event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") & (event_df.xStart <= 66)  & (event_df.xEnd > 66)].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccelsDistIntoFinal3rd\"})\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Acceleration within final third\n",
    "def AccelsWithinFinalThird(event_df):\n",
    "    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") & (event_df.xStart > 66) ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccelsDistWithinFinal3rd\"})\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross assists\n",
    "def crossAssists(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CrossAssists')\n",
    "    df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# right foot crosses\n",
    "def RightFootCross(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('right_foot'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='RightFootCross')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# left foot crosses\n",
    "def LeftFootCross(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('left_foot'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='LeftFootCross')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# cross key passes\n",
    "def CrossKeyPasses(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('key_pass'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CrossKeyPass')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# accurate crosses\n",
    "def AccurateCrosses(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccCrosses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# inaccurate crosses\n",
    "def InaccurateCrosses(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccCrosses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate crosses into penalty box\n",
    "def AccCrossesBox(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') \n",
    "               & (event_df.Result==\"Accurate\") \n",
    "               & (event_df.xEnd > 82)\n",
    "               & (event_df.yEnd < 80)\n",
    "               & (event_df.yEnd > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccCrossesIntoBox')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate crosses into penalty box\n",
    "def InaccCrossesBox(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Cross') \n",
    "               & (event_df.Result==\"Inaccurate\") \n",
    "               & (event_df.xEnd > 82)\n",
    "               & (event_df.yEnd < 80)\n",
    "               & (event_df.yEnd > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccCrossesIntoBox')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tackles & Ground Duels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding tackles won\n",
    "def slidingTacklesWon(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains(\"sliding_tackle won\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SlidingTacklesWon')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Sliding tackles lost\n",
    "def slidingTacklesLost(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains(\"sliding_tackle lost\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SlidingTacklesLost')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground Defending Duels Won\n",
    "def GroundDuelsWon(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"won\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundDefDuelsWon')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground Defending Duels Lost\n",
    "def GroundDuelsLost(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"lost\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundDefDuelsLost')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground Defensive Anticipations\n",
    "def GroundDefAnticipations(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"anticipated\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='DefensiveAnticipations')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground Loose Balls Won\n",
    "def GroundLooseBallsWon(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Ground loose ball duel') &(event_df.subEventDescription.str.contains('won'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundLooseBallsWon')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground Loose Balls Lost\n",
    "def GroundLooseBallsLost(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Ground loose ball duel') &(event_df.subEventDescription.str.contains('lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundLooseBallsLost')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground attacking duels won\n",
    "def GroundAttackDuelsWon(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Ground attacking duel') &(event_df.subEventDescription.str.contains('won'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundAttackDuelsWon')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Ground attacking duels lost\n",
    "def GroundAttackDuelsLost(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Ground attacking duel') &(event_df.subEventDescription.str.contains('lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundAttackDuelsLost')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Offensive Touches in box\n",
    "def OffTouchesBox(event_df):\n",
    "    df = event_df[(event_df.subEventName == 'Touch')\n",
    "              & (event_df.xStart > 82)\n",
    "              & (event_df.yStart < 80)\n",
    "              & (event_df.yStart > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='OffensiveTouchesBox')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shots & Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shots on Target\n",
    "def ShotsOnTarget(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOnTarget')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Shots off Target\n",
    "def ShotsOffTarget(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOffTarget')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Shot opportunity\n",
    "def shot_opportunities(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.contains(\"opportunity\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotOpportunities')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate free kick shots\n",
    "def accFreeKicks(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Free kick shot\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickShotAcc')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate free kick shots\n",
    "def InaccFreeKicks(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Free kick shot\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickShotInacc')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Did not score penalty\n",
    "def PenaltyNotGoal(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Penalty\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltyNotScored')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Goal scored with head/body\n",
    "def HeaderGoal(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "              & (event_df.subEventDescription.str.contains(\"head\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Header/Body_Goal')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df    \n",
    "    \n",
    "# Goal scored with right foot\n",
    "def RightFootGoal(event_df): \n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "              & (event_df.subEventDescription.str.contains(\"right_foot\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='RightFootGoal')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Goal scored with left foot\n",
    "def LeftFootGoal(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "              & (event_df.subEventDescription.str.contains(\"left_foot\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='LeftFootGoal')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Counter Attack Goal\n",
    "def CounterAttackGoal(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "              & (event_df.subEventDescription.str.contains(\"counter_attack\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackGoal')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Interception Goal\n",
    "def InterceptionGoal(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "                & (event_df.subEventDescription.str.contains(\"interception\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InterceptionGoal')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Goal positions\n",
    "def GoalPositions(event_df, pos):\n",
    "    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n",
    "                  & (event_df.subEventDescription.str.contains(pos))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Goal_'+pos)\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "def OwnGoals(event_df):\n",
    "    df = event_df[event_df.subEventDescription.str.contains(\"own\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='OwnGoals')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "def shotAccuracy(event_df):\n",
    "    df1 = event_df[(event_df.subEventName.str.contains('Shot')) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotAccuracy1')\n",
    "    df2 = event_df[(event_df.subEventName.str.contains('Shot')) ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotAccuracy2')\n",
    "    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n",
    "    df1['shotAccuracy'] = df1['ShotAccuracy1'] / df1['ShotAccuracy2']\n",
    "    df1.drop(['ShotAccuracy1', 'ShotAccuracy2'], inplace=True, axis =1)\n",
    "#     df1 = transform_zonal(df, desiredName)\n",
    "    return df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get positional zones of goals for players\n",
    "\n",
    "# possies = ['low_left', 'mid_left', 'high_left', 'low_center', 'mid_center', 'high_center', 'low_right', 'mid_right', 'high_right']\n",
    "# for pos in possies:\n",
    "#     a = GoalPositions(Events_England, pos)\n",
    "#     b = GoalPositions(Events_France, pos)\n",
    "#     c = GoalPositions(Events_Italy, pos)\n",
    "#     d = GoalPositions(Events_Spain, pos)\n",
    "#     e = GoalPositions(Events_Germany, pos)\n",
    "#     df = pd.concat([a,b,c,d,e])\n",
    "#     Player_Aggs = pd.merge(Player_Aggs, df, how= 'left', on =['playerId', 'matchId'])\n",
    "#     Player_Aggs[\"Goal_\"+pos] = Player_Aggs[\"Goal_\"+pos].fillna(0)\n",
    "\n",
    "# Player_Aggs = Player_Aggs.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   Air duel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AerialDuelsWon(events_df):\n",
    "    df = Events_England[(Events_England.subEventName==\"Air duel\") & (Events_England.subEventDescription.str.contains(\"won\"))].groupby(['playerId', 'matchId', 'ZoneStart']).size().reset_index(name='AerialDuelsWon')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "def AerialDuelsLost(events_df):\n",
    "    df =  Events_England[(Events_England.subEventName==\"Air duel\") & (Events_England.subEventDescription.str.contains(\"lost\"))].groupby(['playerId', 'matchId', 'ZoneStart']).size().reset_index(name='AerialDuelsLost')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurate forward passes\n",
    "def acc_forward_pass(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Simple pass\") \n",
    "                   & (event_df.attackMetres>0)\n",
    "                   & (event_df.Result==\"Accurate\")\n",
    "                   & (event_df.subEventDescription.str.match('generic play'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateForwardPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate forward passes \n",
    "def inacc_forward_passes(event_df):\n",
    "    df = event_df[(event_df.subEventName==\"Simple pass\") \n",
    "                   & (event_df.attackMetres>0)\n",
    "                   & (event_df.Result==\"Inaccurate\")\n",
    "                   & (event_df.subEventDescription.str.match('generic play'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateForwardPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# SuccessfulInterceptions ## when a player intercepts a play and makes a successful subsequent play\n",
    "def success_intercept(event_df):\n",
    "    df = event_df[(event_df.Result == 'Accurate')\n",
    "                   & (event_df.subEventDescription.str.match('interception'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulInterceptions')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# CounterAttackInterceptions\n",
    "def CounterAttackIntercepts(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.match('counter_attack interception'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackIntercept')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# DangerousBallLostPassing\n",
    "def dangerous_ball_lost(event_df):\n",
    "    df = event_df[(event_df.subEventName.str.contains(\"pass\")) \n",
    "                   & (event_df.subEventDescription.str.match('dangerous_ball_lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassLostDangerous')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Counter attack involvements\n",
    "def CounterAttackInvolvements(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.match('counter_attack')) \n",
    "                  & (event_df.Result == 'Accurate') ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackInvolvements')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Total Assists\n",
    "def total_assists(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('assist')) \n",
    "                  & (event_df.Result == 'Accurate') ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='TotalAssists')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate Keypasses\n",
    "def inacc_key_passes(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('key_pass')) \n",
    "                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateKeyPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Keypasses\n",
    "def acc_keypasses(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('key_pass')) \n",
    "                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateKeyPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Through Passes\n",
    "def acc_throughs(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('through')) \n",
    "                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateThroughPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "# Inaccurate Through Passes\n",
    "def inacc_throughs(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('through')) \n",
    "                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateThroughPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Smart Passes \n",
    "def acc_smart_passes(event_df):\n",
    "    df = event_df[(event_df.subEventName.str.match('Smart pass')) \n",
    "                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateSmartPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate Smart Passes \n",
    "def inacc_smartPasses(event_df):\n",
    "    df = event_df[(event_df.subEventName.str.match('Smart pass')) \n",
    "                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateSmartPasses')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Through passes into final third\n",
    "def throughs_into_final(event_df):\n",
    "    df = event_df[(event_df.subEventDescription.str.contains('through')) \n",
    "                  & (event_df.xStart < 67 ) \n",
    "                  & (event_df.xEnd > 66 ) \n",
    "                 & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccThroughsIntoFinalThird')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Passes into final third\n",
    "def accPasses_into_final(event_df):\n",
    "    df = event_df[ ( event_df.subEventName.str.contains('pass'))\n",
    "        & (event_df.xStart < 67 ) \n",
    "                  & (event_df.xEnd > 66) \n",
    "                 & (event_df.Result == \"Accurate\")\n",
    "                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccPassesIntoFinalThird')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Passes into final third\n",
    "def InaccPasses_into_final(event_df):\n",
    "    df = event_df[ ( event_df.subEventName.str.contains('pass'))\n",
    "        & (event_df.xStart < 67 ) \n",
    "                  & (event_df.xEnd > 66) \n",
    "                 & (event_df.Result == \"Inaccurate\")\n",
    "                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccPassesIntoFinalThird')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Accurate Passes within final third\n",
    "def accPasses_within_finalThird(event_df):\n",
    "    df = event_df[ (event_df.subEventName.str.contains(\"pass\") )\n",
    "                   & (event_df.xStart > 66 ) \n",
    "                  & (event_df.xEnd > 66 ) \n",
    "                 & (event_df.Result == \"Accurate\")\n",
    "                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccPassesWithinFinalThird')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n",
    "\n",
    "# Inaccurate Passes within final third   \n",
    "def inaccPasses_within_finalThird(event_df):\n",
    "    df = event_df[ (event_df.subEventName.str.contains(\"pass\") )\n",
    "                   & (event_df.xStart > 66 ) \n",
    "                  & (event_df.xEnd > 66) \n",
    "                 & (event_df.Result == \"Inaccurate\")\n",
    "                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccPassesWithinFinalThird')\n",
    "#     df = transform_zonal(df, desiredName)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortLongPassRatio(event_df):\n",
    "    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n",
    "    df1 = event_df[(event_df.subEventName.str.contains('pass')) & ((event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n",
    "    df2 = event_df[(event_df.subEventName.str.contains('pass')) & (((event_df.attackMetres)>20) | (abs(event_df.lateralMetres>20))) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n",
    "    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n",
    "    df1['shortLongPassRatio'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n",
    "    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n",
    "#     df1 = transform_zonal(df, desiredName)\n",
    "    return df1\n",
    "\n",
    "def longPassAccuracy(event_df):\n",
    "    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n",
    "    df1 = event_df[(event_df.subEventName.str.contains('pass')) & ((abs(event_df.attackMetres)>20) | abs(event_df.lateralMetres>20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n",
    "    df2 = event_df[(event_df.subEventName.str.contains('pass')) & ((abs(event_df.attackMetres)>20) | abs(event_df.lateralMetres>20)) ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n",
    "    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n",
    "    df1['longPassAccuracy'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n",
    "    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n",
    "#     df1 = transform_zonal(df, desiredName)\n",
    "    return df1\n",
    "\n",
    "def shortPassAccuracy(event_df):\n",
    "    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n",
    "    df1 = event_df[(event_df.subEventName.str.contains('pass')) & (abs(event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n",
    "    df2 = event_df[(event_df.subEventName.str.contains('pass'))& (abs(event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20))  ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n",
    "    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n",
    "    df1['shortPassAccuracy'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n",
    "    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events_England[\"ReceivingPlayer\"] = Events_England['playerId'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Live match analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveTimes = []\n",
    "for time in range(600, 6000, 600):\n",
    "    liveTimes.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### path = os.getcwd()\n",
    "# Events_England.to_csv(path+'/Events_England_processed')\n",
    "# Events_France.to_csv(path+'/Events_France_processed')\n",
    "# Events_Italy.to_csv(path+'/Events_Italy_processed')\n",
    "# Events_Spain.to_csv(path+'/Events_Spain_processed')\n",
    "# Events_Germany.to_csv(path+'/Events_Germany_processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Events_England_live = Events_England[Events_England.eventSec <= liveTime]\n",
    "# Events_France_live = Events_France[Events_France.eventSec <= liveTime]\n",
    "# Events_Italy_live = Events_Italy[Events_Italy.eventSec <= liveTime]\n",
    "# Events_Spain_live = Events_Spain[Events_Spain.eventSec <= liveTime]\n",
    "# Events_Germany_live = Events_Germany[Events_Germany.eventSec <= liveTime]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Player_Aggs_live = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, position_df, how = 'right', on= 'playerId').sort_values('matchId')\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, p_refs, on = ['matchId', 'playerId'])\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, Teams[['teamId', 'name']], on = 'teamId')\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\n",
    "Player_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.homeTeamId, 'homeAway'] = \"home\"\n",
    "Player_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.awayTeamId, 'homeAway'] = \"away\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playerGameTime_live(event_df, time):\n",
    "    df = event_df.groupby(['matchId','playerId'])['eventSec'].agg([ 'min']).reset_index()\n",
    "    df['liveTime'] = time\n",
    "    df['gameTime (min)'] = round((df['liveTime'] - df['min'])/60) # game time to the nearest minute\n",
    "    # Classify Match Result as W, L or D for teams\n",
    "    conditions = [\n",
    "        (df['gameTime (min)']  < 1),\n",
    "        (df['gameTime (min)'] > 0)\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [0, df['gameTime (min)'].max()]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['gameTime (min)'] = np.select(conditions, values)\n",
    "    \n",
    "    df.drop(['liveTime', 'min'], inplace=True, axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function for event_df parsing\n",
    "def parseEvent_df_live(func, new_feature, time, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live):\n",
    "    \n",
    "    aa = func(df_England_live)\n",
    "    aa = transform_zonal(aa, new_feature)\n",
    "    bb = func(df_France_live)\n",
    "    bb = transform_zonal(bb, new_feature)\n",
    "    cc = func(df_Italy_live)\n",
    "    cc = transform_zonal(cc, new_feature)\n",
    "    dd = func(df_Spain_live)\n",
    "    dd = transform_zonal(dd, new_feature)\n",
    "    ee = func(df_Germany_live)\n",
    "    ee = transform_zonal(ee, new_feature)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        return pd.concat([aa,bb,cc,dd,ee])\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for adding new feature column to Player_Aggs df\n",
    "\n",
    "def alter_Player_Aggs_live(new_feature_function, new_feature, PA_df, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live):\n",
    "\n",
    "    df = parseEvent_df_live(new_feature_function, new_feature, time, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live)\n",
    "\n",
    "    try:\n",
    "        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n",
    "    \n",
    "    except:\n",
    "        return PA_df\n",
    "    \n",
    "    return PA_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs_live = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, position_df, how = 'right', on= 'playerId').sort_values('matchId')\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, p_refs, on = ['matchId', 'playerId'])\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, Teams[['teamId', 'name']], on = 'teamId')\n",
    "Player_Aggs_live = pd.merge(Player_Aggs_live, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\n",
    "Player_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.homeTeamId, 'homeAway'] = \"home\"\n",
    "Player_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.awayTeamId, 'homeAway'] = \"away\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkies = [AccBackwardMetres, InaccBackwardMetres, AccForwardMetres, InaccForwardMetres, SimulationFouls, Fouls, Clearances, AccLaunchMetres, InaccLaunchMetres, FreeKickCrossKey, FreeKickCrossAccuracy, dangerousOpponentHalfRecoveries, dangerousOwnHalfBallLost, dangerousDefDuelsLost, Saves, LeavingLine, SuccessAccelerations, FailedAccelerations, AccelDistance, AccelsIntoFinalThird, AccelsWithinFinalThird, RightFootCross, LeftFootCross, CrossKeyPasses, AccurateCrosses, InaccurateCrosses, AccCrossesBox, InaccCrossesBox, slidingTacklesWon, slidingTacklesLost, GroundDuelsWon, GroundDuelsLost, GroundDefAnticipations, GroundLooseBallsWon, GroundLooseBallsLost, GroundAttackDuelsWon, GroundAttackDuelsLost, OffTouchesBox, ShotsOnTarget, ShotsOffTarget, shot_opportunities, accFreeKicks, InaccFreeKicks, PenaltyNotGoal, AerialDuelsWon, AerialDuelsLost, inaccPasses_within_finalThird, accPasses_within_finalThird, accPasses_into_final, InaccPasses_into_final, throughs_into_final, inacc_smartPasses, acc_smart_passes, inacc_throughs, acc_throughs, acc_keypasses, inacc_key_passes, CounterAttackInvolvements, dangerous_ball_lost, CounterAttackIntercepts, success_intercept, inacc_forward_passes, acc_forward_pass, corner_assists, corner_opportunity, corner_success, corner_fail]\n",
    "# var_noms = [\"AccBackMetres\",  \"InaccBackMetres\",  \"AccForwardMetres\",  \"InaccForwardMetres\",  \"SimulationFouls\",  \"FoulsCommited\",  \"Clearances\",  \"AccLaunchMetres\",  \"InaccLaunchMetres\",  \"FKKeyCross\",  \"AccFreeKickCrosses\",  \"dangerousOpponentHalfRecoveries\",  \"dangerousOwnHalfBallLost\",  \"dangerousDefDuelsLost\",  \"GkSaves\", \"GKLeavingLineInstance\",  \"SuccessfulAccels\",  \"FailedAccels\",  \"CumAccelerationDist\",  \"AccelsDistIntoFinal3rd\",  \"AccelsDistWithinFinal3rd\",  \"RightFootCross\",  \"LeftFootCross\",  \"CrossKeyPass\",  \"AccCrosses\",  \"InaccCrosses\",  \"AccCrossesIntoBox\",  \"InaccCrossesIntoBox\",  \"SlidingTacklesWon\",  \"SlidingTacklesLost\",  \"GroundDefDuelsWon\",  \"GroundDefDuelsLost\",  \"DefensiveAnticipations\",  \"GroundLooseBallsWon\",  \"GroundLooseBallsLost\",  \"GroundAttackDuelsWon\",  \"GroundAttackDuelsLost\",  \"OffensiveTouchesBox\",  \"ShotsOnTarget\",  \"ShotsOffTarget\",  \"ShotOpportunities\",  \"FreeKickShotAcc\",  \"FreeKickShotInacc\",  \"PenaltyNotScored\",  \"AerialDuelsWon\",  \"AerialDuelsLost\",  \"InaccPassesWithinFinalThird\",  \"AccPassesWithinFinalThird\",  \"AccPassesIntoFinalThird\",  \"InaccPassesIntoFinalThird\",  \"AccThroughsIntoFinalThird\",  \"InaccurateSmartPasses\",  \"AccurateSmartPasses\",  \"InaccurateThroughPasses\",  \"AccurateThroughPasses\",  \"AccurateKeyPasses\",  \"InaccurateKeyPasses\",  \"CounterAttackInvolvements\",  \"PassLostDangerous\",  \"CounterAttackIntercept\",  \"SuccessfulInterceptions\",  \"InaccurateForwardPasses\",  \"AccurateForwardPasses\",  \"CornerAssists\",  \"CornerOpportunitiesCreated\",  \"SuccessfulCorners\",  \"FailedCorners\"]\n",
    "    \n",
    "    \n",
    "# for indx in range(len(funkies)):\n",
    "#     Player_Aggs2 = alter_Player_Aggs(funkies[indx], var_noms[indx], Player_Aggs2)\n",
    "#     Player_Aggs2 = Player_Aggs2.drop_duplicates()\n",
    "#     remove_col = [col for col in Player_Aggs2 if col.endswith(\"_0\")]\n",
    "#     if remove_col:\n",
    "#         Player_Aggs2.drop(columns = remove_col, inplace=True, axis=1)\n",
    "\n",
    "# Player_Aggs2 = Player_Aggs2.loc[:, (Player_Aggs2 != 0).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Live Match # # #\n",
    "\n",
    "def get_live_players(player_aggs_live, time):\n",
    "    \n",
    "    # derive gameTime per player and store in summary table\n",
    "    a = playerGameTime_live(Events_England, time)\n",
    "    b = playerGameTime_live(Events_France, time)\n",
    "    c = playerGameTime_live(Events_Italy, time)\n",
    "    d = playerGameTime_live(Events_Spain, time)\n",
    "    e = playerGameTime_live(Events_Germany, time)\n",
    "\n",
    "    playingTime_live = pd.concat([a,b,c,d,e])\n",
    "\n",
    "    player_aggs_live = pd.merge(player_aggs_live, playingTime_live, how = 'left', on = ['playerId', 'matchId'])\n",
    "\n",
    "    funkies = [AccBackwardMetres, InaccBackwardMetres, AccForwardMetres, InaccForwardMetres, SimulationFouls, Fouls, Clearances, AccLaunchMetres, InaccLaunchMetres, FreeKickCrossKey, FreeKickCrossAccuracy, dangerousOpponentHalfRecoveries, dangerousOwnHalfBallLost, dangerousDefDuelsLost, Saves, LeavingLine, SuccessAccelerations, FailedAccelerations, AccelDistance, AccelsIntoFinalThird, AccelsWithinFinalThird, RightFootCross, LeftFootCross, CrossKeyPasses, AccurateCrosses, InaccurateCrosses, AccCrossesBox, InaccCrossesBox, slidingTacklesWon, slidingTacklesLost, GroundDuelsWon, GroundDuelsLost, GroundDefAnticipations, GroundLooseBallsWon, GroundLooseBallsLost, GroundAttackDuelsWon, GroundAttackDuelsLost, OffTouchesBox, ShotsOnTarget, ShotsOffTarget, shot_opportunities, accFreeKicks, InaccFreeKicks, PenaltyNotGoal, AerialDuelsWon, AerialDuelsLost, inaccPasses_within_finalThird, accPasses_within_finalThird, accPasses_into_final, InaccPasses_into_final, throughs_into_final, inacc_smartPasses, acc_smart_passes, inacc_throughs, acc_throughs, acc_keypasses, inacc_key_passes, CounterAttackInvolvements, dangerous_ball_lost, CounterAttackIntercepts, success_intercept, inacc_forward_passes, acc_forward_pass, corner_assists, corner_opportunity, corner_success, corner_fail]\n",
    "    var_noms = [\"AccBackMetres\",  \"InaccBackMetres\",  \"AccForwardMetres\",  \"InaccForwardMetres\",  \"SimulationFouls\",  \"FoulsCommited\",  \"Clearances\",  \"AccLaunchMetres\",  \"InaccLaunchMetres\",  \"FKKeyCross\",  \"AccFreeKickCrosses\",  \"dangerousOpponentHalfRecoveries\",  \"dangerousOwnHalfBallLost\",  \"dangerousDefDuelsLost\",  \"GkSaves\", \"GKLeavingLineInstance\",  \"SuccessfulAccels\",  \"FailedAccels\",  \"CumAccelerationDist\",  \"AccelsDistIntoFinal3rd\",  \"AccelsDistWithinFinal3rd\",  \"RightFootCross\",  \"LeftFootCross\",  \"CrossKeyPass\",  \"AccCrosses\",  \"InaccCrosses\",  \"AccCrossesIntoBox\",  \"InaccCrossesIntoBox\",  \"SlidingTacklesWon\",  \"SlidingTacklesLost\",  \"GroundDefDuelsWon\",  \"GroundDefDuelsLost\",  \"DefensiveAnticipations\",  \"GroundLooseBallsWon\",  \"GroundLooseBallsLost\",  \"GroundAttackDuelsWon\",  \"GroundAttackDuelsLost\",  \"OffensiveTouchesBox\",  \"ShotsOnTarget\",  \"ShotsOffTarget\",  \"ShotOpportunities\",  \"FreeKickShotAcc\",  \"FreeKickShotInacc\",  \"PenaltyNotScored\",  \"AerialDuelsWon\",  \"AerialDuelsLost\",  \"InaccPassesWithinFinalThird\",  \"AccPassesWithinFinalThird\",  \"AccPassesIntoFinalThird\",  \"InaccPassesIntoFinalThird\",  \"AccThroughsIntoFinalThird\",  \"InaccurateSmartPasses\",  \"AccurateSmartPasses\",  \"InaccurateThroughPasses\",  \"AccurateThroughPasses\",  \"AccurateKeyPasses\",  \"InaccurateKeyPasses\",  \"CounterAttackInvolvements\",  \"PassLostDangerous\",  \"CounterAttackIntercept\",  \"SuccessfulInterceptions\",  \"InaccurateForwardPasses\",  \"AccurateForwardPasses\",  \"CornerAssists\",  \"CornerOpportunitiesCreated\",  \"SuccessfulCorners\",  \"FailedCorners\"]\n",
    "    \n",
    "    Events_England_live = Events_England[Events_England.eventSec <= time]\n",
    "    Events_France_live = Events_France[Events_France.eventSec <= time]\n",
    "    Events_Italy_live = Events_Italy[Events_Italy.eventSec <= time]\n",
    "    Events_Spain_live = Events_Spain[Events_Spain.eventSec <= time]\n",
    "    Events_Germany_live = Events_Germany[Events_Germany.eventSec <= time]\n",
    "    \n",
    "    for indx in range(len(funkies)):\n",
    "        player_aggs_live = alter_Player_Aggs_live(funkies[indx], var_noms[indx], player_aggs_live, Events_England_live, Events_France_live, Events_Italy_live, Events_Spain_live, Events_Germany_live)\n",
    "        player_aggs_live = player_aggs_live.drop_duplicates()\n",
    "        remove_col = [col for col in player_aggs_live if col.endswith(\"_0\")]\n",
    "        if remove_col:\n",
    "            player_aggs_live.drop(columns = remove_col, inplace=True, axis=1)  \n",
    "\n",
    "    player_aggs_live.iloc[:,15:] = player_aggs_live.iloc[:,15:].fillna(0)\n",
    "    player_aggs_live.iloc[:,15:] = player_aggs_live.iloc[:,15:].div(player_aggs_live[\"gameTime (min)\"], axis =0).fillna(0)*90\n",
    "    player_aggs_live = player_aggs_live.loc[:, (player_aggs_live != 0).any(axis=0)]\n",
    "    \n",
    "    return player_aggs_live\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player_Aggs_live10 = get_live_players(Player_Aggs_live, 600)\n",
    "# Player_Aggs_live20 = get_live_players(Player_Aggs_live, 1200)\n",
    "# Player_Aggs_live30 = get_live_players(Player_Aggs_live, 1800)\n",
    "# Player_Aggs_live40 = get_live_players(Player_Aggs_live, 2400)\n",
    "# Player_Aggs_live50 = get_live_players(Player_Aggs_live, 3000)\n",
    "# Player_Aggs_live60 = get_live_players(Player_Aggs_live, 3600)\n",
    "# Player_Aggs_live70 = get_live_players(Player_Aggs_live, 4200)\n",
    "# Player_Aggs_live80 = get_live_players(Player_Aggs_live, 4800)\n",
    "Player_Aggs_live90 = get_live_players(Player_Aggs_live, 5400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/group/interns202010/jmakins/Data/events')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('/kaggle/input/youwot')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/kaggle/input/youwot', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('/kaggle/input/youwot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.getcwd()\n",
    "\n",
    "# Player_Aggs_live10.to_csv(path+'/Player_Aggs_live10')\n",
    "# Player_Aggs_live20.to_csv(path+'/Player_Aggs_live20')\n",
    "# Player_Aggs_live30.to_csv(path+'/Player_Aggs_live30')\n",
    "# Player_Aggs_live40.to_csv(path+'/Player_Aggs_live40')\n",
    "# Player_Aggs_live50.to_csv(path+'/Player_Aggs_live50')\n",
    "# Player_Aggs_live60.to_csv(path+'/Player_Aggs_live60')\n",
    "# Player_Aggs_live70.to_csv(path+'/Player_Aggs_live70')\n",
    "# Player_Aggs_live80.to_csv(path+'/Player_Aggs_live80')\n",
    "# Player_Aggs_live90.to_csv(path+'/Player_Aggs_live90')\n",
    "\n",
    "# Player_Aggs_live10 = pd.read_csv('Player_Aggs_live10')\n",
    "# Player_Aggs_live10.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live20= pd.read_csv('Player_Aggs_live20')\n",
    "# Player_Aggs_live20.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live30= pd.read_csv('Player_Aggs_live30')\n",
    "# Player_Aggs_live30.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live40= pd.read_csv('Player_Aggs_live40')\n",
    "# Player_Aggs_live40.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live50= pd.read_csv('Player_Aggs_live50')\n",
    "# Player_Aggs_live50.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live60= pd.read_csv('Player_Aggs_live60')\n",
    "# Player_Aggs_live60.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live70= pd.read_csv('Player_Aggs_live70')\n",
    "# Player_Aggs_live70.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live80= pd.read_csv('Player_Aggs_live80')\n",
    "# Player_Aggs_live80.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "# Player_Aggs_live90= pd.read_csv('Player_Aggs_live90')\n",
    "# Player_Aggs_live90.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn import metrics \n",
    "from scipy.spatial.distance import cdist \n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.patches as patches\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from random import seed\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del Player_Aggs_live40\n",
    "    del Player_Aggs_live20\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs_live90 = pd.read_csv('Player_Aggs_live90')\n",
    "Player_Aggs_live90.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "# Events_England = pd.read_csv('eventsEvents_England_processed')\n",
    "# Events_Italy = pd.read_csv('eventsEvents_Italy_processed')\n",
    "# Events_Germany = pd.read_csv('eventsEvents_Germany_processed')\n",
    "# Events_France = pd.read_csv('eventsEvents_France_processed')\n",
    "# Events_Spain = pd.read_csv('eventsEvents_Spain_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matches_df_fDNN(TAM):\n",
    "    df2 = TAM.groupby('matchId').agg(list).reset_index()\n",
    "    df2.drop([\"Result\",\"homeTeamId\", \"awayTeamId\", \"height\", \"weight\", 'playerId', \"xStart\", \"yStart\", \"gameTime (min)\"], inplace=True, axis=1)\n",
    "\n",
    "    df4 = pd.concat([df2, pd.DataFrame(df2['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n",
    "    df4.drop([\"teamId\"], inplace=True, axis = 1)\n",
    "    result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n",
    "\n",
    "\n",
    "    df3 = result.iloc[:,-4:]\n",
    "    for var in list(result.columns)[1:-4]:\n",
    "\n",
    "        df3 = pd.concat([df3, pd.DataFrame(result[var].to_list(), columns=[\"1_\" + var, \"2_\" + var])], axis=1, sort = False)\n",
    "\n",
    "        # Correctly apply allocate home and away aggregate statistics to correct teams\n",
    "        df3['home'+var] = (\n",
    "            np.select(\n",
    "                condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n",
    "                choicelist=[df3[\"1_\" + var], df3[\"2_\" + var]]))\n",
    "\n",
    "        df3['away'+var] = (\n",
    "            np.select(\n",
    "                condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n",
    "                choicelist=[df3[\"1_\" + var], df3[\"2_\" + var]]))\n",
    "\n",
    "        # # drop useless columns that have been replaced\n",
    "        df3.drop([ \"1_\" + var, \"2_\" + var], inplace = True, axis = 1 )\n",
    "\n",
    "    df3 = pd.concat([result[['matchId']],df3], axis=1)\n",
    "    df3 = pd.merge(df3, Matches[[\"matchId\", \"Result\"]], how =\"inner\", on='matchId')\n",
    "    df3.drop([\"team1\", \"team2\"], axis=1, inplace=True)\n",
    "\n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team_Aggs_Matches = Player_Aggs_live90.groupby(['matchId', 'teamId' ]).sum().reset_index()\n",
    "Team_Aggs_Matches = pd.merge(Team_Aggs_Matches, Matches[['matchId', \"Result\"]], how = 'left', on = 'matchId' )\n",
    "result = Matches_df_fDNN(Team_Aggs_Matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = result.loc[:, ~result.columns.isin([\"Result\",'teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\n",
    "y_all = result[\"Result\"].values\n",
    "X_all = X_all.replace([np.inf, -np.inf], np.nan)\n",
    "X_all = X_all.fillna(X_all.mean())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = RandomForestClassifier(n_estimators = 500, random_state=123, max_depth = 5)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-1,0,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, labels = labels))\n",
    "print('accuracy score: {0:.4f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Result'], colnames=['Predicted Result']))\n",
    "class_name = list(set(y_test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (16, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame(clf.feature_importances_, index=X_all.columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance[0:20].plot(kind='bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainD, X_testD, y_trainD, y_testD = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler().fit(X_trainD)\n",
    "\n",
    "# X_trainD = scaler.transform(X_trainD)\n",
    "\n",
    "# X_testD = scaler.transform(X_testD)\n",
    "\n",
    "# X_testD2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define per-fold score containers\n",
    "# acc_per_fold = []\n",
    "# loss_per_fold = []\n",
    "\n",
    "# kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# fold_no=1\n",
    "\n",
    "# for train, test in kfold.split(X_trainD, y_trainD):\n",
    "    \n",
    "#     dnn = Sequential()\n",
    "#     #dnn.add(Flatten(input_shape=(500,3)))\n",
    "#     #dnn.add(Dense(512, activation='relu',kernel_initializer = 'he_normal'))\n",
    "#     #dnn.add(Dropout(0.3))\n",
    "#     dnn.add(Dense(256, activation='relu', kernel_initializer = 'he_normal' ,input_shape=(X_testD2.shape[1],)))\n",
    "#     dnn.add(Dropout(0.4))\n",
    "#     dnn.add(Dense(128, activation='relu',kernel_initializer = 'he_normal'))\n",
    "#     dnn.add(Dropout(0.4))\n",
    "#     dnn.add(Dense(64, activation='relu',kernel_initializer = 'he_normal'))\n",
    "#     dnn.add(Dropout(0.4))\n",
    "#     dnn.add(Dense(1, activation='sigmoid',kernel_initializer = 'he_normal'))\n",
    "#     #optim = keras.optimizers.SGD(lr=0.01, momentum=0.975, decay=2e-06, nesterov=True)\n",
    "#     opt = keras.optimizers.Adam(learning_rate=0.00000001)\n",
    "\n",
    "\n",
    "#     dnn.compile(loss='categorical_crossentropy',\n",
    "#     optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     #history = model.fit(X_train2, y_train2,\n",
    "#     #batch_size = 32, epochs = 1,  verbose = 2)#, validation_data= (x_valid, y_valid))\n",
    "\n",
    "#     history = dnn.fit(X_trainD[train], y_trainD[train], validation_data = (X_trainD[test], y_trainD[test]), epochs=2500, batch_size=32, verbose =2)\n",
    "\n",
    "#     # batchsize 256\n",
    "#     #lr 0.00001, 0.0001\n",
    "\n",
    "#     print(dnn.summary())\n",
    "\n",
    "#     # Generate generalization metrics\n",
    "#     scores = model.evaluate(X_trainD[test], y_trainD[test], verbose=0)\n",
    "#     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "#     acc_per_fold.append(scores[1] * 100)\n",
    "#     loss_per_fold.append(scores[0])\n",
    "#     # Increase fold number\n",
    "#     fold_no = fold_no + 1\n",
    "\n",
    "# # score = model.evaluate(X_test2, y_test2, verbose=0)\n",
    "# # print('Test loss:', score[0])\n",
    "# # print('Test top 1 accuracy:', score[1])\n",
    "\n",
    "# # == Provide average scores ==\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Score per fold')\n",
    "# for i in range(0, len(acc_per_fold)):\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Average scores for all folds:')\n",
    "# print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "# print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "# print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pred = dnn.predict(X_testD2)\n",
    "# #Converting predictions to label\n",
    "# pred = list()\n",
    "# for i in range(len(y_pred)):\n",
    "#     pred.append(np.argmax(y_pred[i]))\n",
    "# # #Converting one hot encoded test label to label\n",
    "# # test = list()\n",
    "# # for i in range(len(y_test2)):\n",
    "# #     test.append(np.argmax(y_test[i]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = accuracy_score(pred,y_test)\n",
    "# print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = [tree.predict(X_test) for tree in clf.estimators_]\n",
    "X_test2 = np.transpose(X_test2)\n",
    "X_train2 = [tree.predict(X_train) for tree in clf.estimators_]\n",
    "X_train2 = np.transpose(X_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_total = [tree.predict(result) for tree in clf.estimators_]\n",
    "# x_total = np.transpose(x_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_transform(X):\n",
    "    df = []  \n",
    "    for sample in X:\n",
    "        s = []\n",
    "        for feature in sample:\n",
    "            if feature == 2:\n",
    "                s.append([0, 0, 1])\n",
    "            elif feature == 1:\n",
    "                s.append([0, 1, 0])\n",
    "            else:\n",
    "                s.append([1, 0, 0])\n",
    "        df.append(s)\n",
    "    df = np.array(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_transform(X_train2)\n",
    "X_test2 = X_transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape\n",
    "X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one-hot encode the labels\n",
    "def y_transform(Y):\n",
    "    df = []\n",
    "    for l in Y:\n",
    "        if l == 1:\n",
    "            df.append([0, 0, 1])\n",
    "        elif l == 0:\n",
    "            df.append([0, 1, 0])\n",
    "        else:\n",
    "            df.append([1, 0, 0])\n",
    "    df = np.array(df,dtype=int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = y_transform(y_train)\n",
    "y_test2 = y_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train2, X_test3, y_train2, y_test3 = train_test_split(X_train2, y_train2, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train2.shape)\n",
    "print(X_train2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "# # Define per-fold score containers\n",
    "# acc_per_fold = []\n",
    "# loss_per_fold = []\n",
    "\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# fold_no=1\n",
    "\n",
    "# for train, test in kfold.split(X_train2, y_train2):\n",
    "def create_model(learning_rate=0.000001):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(500,3)))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer = 'he_normal' ,input_shape=(500*3,)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128, activation='relu',kernel_initializer = 'he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu',kernel_initializer = 'he_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(3, activation='softmax',kernel_initializer = 'he_normal'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "#     # Generate generalization metrics\n",
    "#     scores = model.evaluate(X_train2[test], y_train2[test], verbose=0)\n",
    "#     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "#     acc_per_fold.append(scores[1] * 100)\n",
    "#     loss_per_fold.append(scores[0])\n",
    "#     # Increase fold number\n",
    "#     fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [16, 32, 64, 128, 256]\n",
    "epochs = [1000, 2000, 2500,3000,3500,4000,5000]\n",
    "learning_rate=[0.0001, 0.00001, 0.000001,0.0000001,0.00000001]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, learning_rate=learning_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_result = grid.fit(X_train2, y_train2)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# grid.result.predict(X_test2)\n",
    "\n",
    "# history = model.fit(X_train2[train], y_train2[train], validation_data = (X_train2[test], y_train2[test]), epochs=2000, batch_size=32, verbose =2)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_result.predict(X_test2)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test2)):\n",
    "    test.append(np.argmax(y_test2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # == Provide average scores ==\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Score per fold')\n",
    "# for i in range(0, len(acc_per_fold)):\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Average scores for all folds:')\n",
    "# print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "# print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "# print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test2)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test2)):\n",
    "    test.append(np.argmax(y_test2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred[i]==2:\n",
    "        pred[i] = 1\n",
    "    elif pred[i]==0:\n",
    "        pred[i]= -1\n",
    "    else:\n",
    "        pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    if test[i]==2:\n",
    "        test[i] = 1\n",
    "    elif test[i]==0:\n",
    "        test[i]= -1\n",
    "    else:\n",
    "        test[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, pred)\n",
    "import seaborn as sns\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.rcParams['font.size'] = 14\n",
    "fig, ax = plt.subplots(1)\n",
    "x_axis_labels,y_axis_labels = [\"Loss\", \"Draw\", \"Win\"], [\"Loss\", \"Draw\", \"Win\"]\n",
    "#sns.color_palette(\"magma\")\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=\"d\", xticklabels=x_axis_labels, yticklabels=y_axis_labels, center=50, linecolor=\"black\", cmap='flag', linewidths=0.2, annot_kws={'size':20},cbar=False), #,cmap=\"PiYG\")\n",
    "plt.xlabel(\"Predicted Result\",  color = \"white\")\n",
    "plt.ylabel(\"Actual Result\",  color = \"white\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-1,0,1]\n",
    "\n",
    "print(classification_report(test, pred, labels = labels,target_names=['Loss', 'Draw', 'Win']))\n",
    "print('accuracy score: {0:.4f}'.format(accuracy_score(test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(np.array(test), np.array(pred), rownames=['Actual Result'], colnames=['Predicted Result']))\n",
    "class_name = list(set(test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBoost DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "        'learning_rate': [0.0001,0.001, 0.01, 0.02,0.1, 0.2, 0.3],\n",
    "        'n_estimators': [100,200,500,1000]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_comb = 5\n",
    "# folds = 5\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "# random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# # Here we go\n",
    "# start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "# random_search.fit(X_train, y_train)\n",
    "# timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "# # xgb.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n All results:')\n",
    "# print(random_search.cv_results_)\n",
    "# print('\\n Best estimator:')\n",
    "# print(random_search.best_estimator_)\n",
    "# print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "# print(random_search.best_score_ * 2 - 1)\n",
    "# print('\\n Best hyperparameters:')\n",
    "# print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE XGB WITH OPTIMIZED PARAMS\n",
    "# Best hyperparameters: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 7, 'learning_rate': 0.2, 'gamma': 1.5, 'colsample_bytree': 0.8}\n",
    "\n",
    "xgb = XGBClassifier(features_names=X_all.columns, gamma=1.5, n_estimators =500, max_depth=7, min_child_weight=5)\n",
    "xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.Series(xgb.booster().get_fscore()).sort_values(ascending=False)\n",
    "# feat_imp.plot(kind='bar', title='Feature Importances')57.1\n",
    "# plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "# plot feature importance\n",
    "plot_importance(xgb, max_num_features=25, ylabel=\"Features\")\n",
    "plt.figure(figsize=(5,5))\n",
    "fig.set_size_inches(6.5, 4.5, forward=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "# plot single tree\n",
    "plot_tree(xgb, num_trees=1, rankdir='LR')\n",
    "#plt.rcParams['figure.figsize'] = [50, 20]\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BREAK sfkldfkjsdkfl asap rocky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RF\", \"fDNN\", \"xgboost\"]\n",
    "minutes = [10,20,30,40,50,60,70,80,90]\n",
    "x = list(range(9))\n",
    "fdnn = []\n",
    "xb = []\n",
    "rf = []\n",
    "\n",
    "accuracies = [47.54, 47.55, 46.17, 50.55, 59.56, 46.72, 50.82, 54.10, 51.37, 51.91, 57.377, 57.10, 51.64, 54.92, 59.02, 53.01, 59.56, 52.8, 52.19, 57.38, 59.84, 53.55, 60.11, 63.93, 53.55, 64.481, 64.75]\n",
    "for i in range(0,27,3):\n",
    "    try:\n",
    "        rf.append(accuracies[i])\n",
    "        fdnn.append(accuracies[i+1])\n",
    "        xb.append(accuracies[i+2])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'RF': rf, \"fDNN\": fdnn, \"XGBoost\": xb, \"Minutes\": minutes})\n",
    "\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#plt.style.use('seaborn-darkgrid')\n",
    "#my_dpi=96\n",
    "fig = plt.figure(figsize=(480/my_dpi, 480/my_dpi), dpi=my_dpi)\n",
    "fig.patch.set_facecolor('#241C24')\n",
    "\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Dark2')\n",
    " \n",
    "# multiple line plot\n",
    "\n",
    "plt.plot(df['Minutes'], df[\"RF\"], marker='', color=\"#fbc5ff\", linewidth=2, alpha=0.8, label=\"RF\")\n",
    "plt.plot(df['Minutes'], df[\"XGBoost\"], marker='', color=\"#357ffd\", linewidth=2, alpha=0.4, label=\"XGBoost\")\n",
    "plt.plot(df['Minutes'], df[\"fDNN\"], marker='', color=\"#c197d2\", linewidth=4, alpha=1, label=\"fDNN\")\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc=2, ncol=2)\n",
    "    \n",
    "# Change xlim\n",
    "plt.xlim(0,100)\n",
    " \n",
    "# Add titles\n",
    "plt.title(\"fDNN vs Random Forest and XGBoost\", loc='left', fontsize=16, fontweight=0, color='white')\n",
    "plt.xlabel(\"Minutes\", color = 'white', size = 14)\n",
    "plt.ylabel(\"Accuracy Score\", color = 'white', size=14)\n",
    "plt.xticks(color=\"white\")\n",
    "plt.yticks(color=\"white\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Tactics and Automated Subs / Formation Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udfs ----\n",
    "\n",
    "# function for creating a feature importance dataframe\n",
    "def imp_df(column_names, importances):\n",
    "    df = pd.DataFrame({'feature': column_names,\n",
    "                       'feature_importance': importances}) \\\n",
    "           .sort_values('feature_importance', ascending = False) \\\n",
    "           .reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "# plotting a feature importance dataframe (horizontal barchart)\n",
    "def var_imp_plot(imp_df, title):\n",
    "    imp_df.columns = ['feature', 'feature_importance']\n",
    "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n",
    "       .set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_tactics = Player_Aggs_live20.groupby(['matchId', 'teamId']).sum().reset_index()\n",
    "team_tactics.drop([\"playerId\", 'weight', 'height', 'xStart', 'yStart', 'homeTeamId', 'awayTeamId', 'gameTime (min)' ], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_result(team_df):\n",
    "    \n",
    "    df = pd.merge(team_df, Matches[[\"homeTeamId\", \"awayTeamId\",\"matchId\", \"Result\"]], how = \"left\", on = [\"matchId\"])\n",
    "    \n",
    "    # Classify Match W, L or D for a team\n",
    "    conditions = [\n",
    "        ((df['homeTeamId'] == df.teamId) &(df.Result==1)),\n",
    "        ((df['homeTeamId'] == df.teamId)&(df.Result==0)),\n",
    "        ((df['homeTeamId'] == df.teamId)&(df.Result==-1)),\n",
    "        ((df['awayTeamId'] == df.teamId)&(df.Result==1)),\n",
    "        ((df['awayTeamId'] == df.teamId)&(df.Result==0)),\n",
    "        ((df['awayTeamId'] == df.teamId)&(df.Result==-1))\n",
    "        ]\n",
    "\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    values = [1,0,-1,-1,0,1]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['result'] = np.select(conditions, values)\n",
    "    df.drop([\"Result\"], axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = team_result(team_tactics)\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(None, columns = team_tactics.columns)\n",
    "\n",
    "# for team in teams:\n",
    "#     test = team_tactics[team_tactics.teamId == team]\n",
    "#     data = team_result(team, test)\n",
    "#     df = df.append(data, ignore_index=True)\n",
    "\n",
    "# df = df.replace([np.inf, -np.inf], np.nan)\n",
    "# df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df.iloc[:,2:-1]\n",
    "y_all = df.result.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, random_state=123)\n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determing player ratings for feature importance\n",
    "\n",
    "df1 = Player_Aggs_live20.iloc[:,:15]\n",
    "df2 = Player_Aggs_live20.iloc[:,15:]\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan)\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df2.values)\n",
    "df2 = pd.DataFrame(x_scaled, columns = df2.columns)\n",
    "\n",
    "base_imp = imp_df(df2.columns, rf.feature_importances_)\n",
    "xxx = base_imp.transpose()\n",
    "xxx.columns = xxx.iloc[0]\n",
    "xxx = xxx.drop(xxx.index[[0]])\n",
    "xxx = xxx.reindex(sorted(xxx.columns), axis=1)\n",
    "df2 = df2.reindex(sorted(df2.columns), axis=1)\n",
    "df2 = df2.multiply(xxx.values)\n",
    "negatives = df2.filter(regex='Inacc|Lost|Fouls|Fail|Not|Leaving').columns\n",
    "df2[negatives] = df2[negatives].multiply(-1)\n",
    "df2[\"sum\"] = df2.iloc[:,:-1].sum(axis=1)\n",
    "df2 = pd.concat([df1, df2], axis=1)\n",
    "df2 = pd.merge(df2, df[[\"matchId\", 'teamId', \"result\"]], on =['matchId', \"teamId\"], how = 'left' )\n",
    "#df2 = df2.loc[:, (df2 != 0).any(axis=0)]\n",
    "df2['playerRatings']=  np.where(df2['gameTime (min)'] ==0, 0, df2['sum'])\n",
    "df2['playerRatings'] = df2['playerRatings'].multiply(94 / float(df2.playerRatings.nlargest(5)[-1:]))\n",
    "df2['playerRatings'] = np.where(df2['playerRatings'] > 94.0, 94, df2['playerRatings'])\n",
    "df2.drop([\"sum\"], axis=1, inplace=True)\n",
    "collections.Counter(df2.sort_values(\"playerRatings\", ascending=False).iloc[0:100,:].Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting player performance in a specific match for automated tactical sub recommendations (underperforming players)\n",
    "df2[df2.matchId==2499725].sort_values(\"playerRatings\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_values = df2.sort_values(\"playerRatings\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = player_values.groupby([\"shortName\", 'playerId', \"teamId\", \"Position\"]).sum().reset_index().sort_values(\"playerRatings\", ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['purple','#c197d2','pink'] #navy\n",
    "fig =plt.figure()\n",
    "ax = test.head(100).groupby('Position')[\"playerRatings\"].nunique().plot(kind='bar',  color=colors, )\n",
    "ax.patch.set_facecolor('#241C24')\n",
    "fig.patch.set_facecolor('#241C24')\n",
    "ax.tick_params(axis='x', colors='white',size =16 )\n",
    "ax.tick_params(axis='y', colors='white', size=16)\n",
    "plt.ylabel(\"Number of Players\", color = \"white\", size = 12)\n",
    "plt.xlabel(\"Positions\", color = \"white\", size=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"PR_perMatch\"] = 100*test[\"playerRatings\"] / test[\"gameTime (min)\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = df2.groupby([\"teamId\", 'matchId', \"result\"]).sum().reset_index().sort_values(\"matchId\")\n",
    "trial.drop([\"gameTime (min)\", \"homeTeamId\", \"awayTeamId\", \"xStart\", \"yStart\", \"playerId\", \"height\", \"weight\"], axis=1, inplace=True)\n",
    "trial[\"x\"] = list(range(1,len(trial)+1))\n",
    "trial.rename(columns={\"playerRatings\": \"teamRatings\"}, inplace=True)\n",
    "\n",
    "# # Classify Match Result as W, L or D for teams\n",
    "# conditions = [\n",
    "#     (trial['result'] == 0),\n",
    "#     (trial['result'] == -1),\n",
    "#     (trial['result'] == 1)\n",
    "#     ]\n",
    "\n",
    "# # create a list of the values we want to assign for each condition\n",
    "# values = [\"D\", \"L\", \"W\"]\n",
    "\n",
    "# # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "# trial['xresult'] = np.select(conditions, values)\n",
    "\n",
    "\n",
    "ax =trial.plot.scatter(x='x',\n",
    "                      y='teamRatings',\n",
    "                      c='result', \n",
    "                  cmap=\"viridis\")                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.iloc[2:3,0:1] =  \"M.Hamsik\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"PR_perMatch\"] = test[\"PR_perMatch\"].multiply(94 / float(test.PR_perMatch.max()))# normalize player ratings per match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test = test.rename(columns= {\"shortName\": \"Name\"})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    test = test.rename(columns= {\"gameTime (min)\": \"Mins Played\"})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(\"playerRatings\", ascending=False).round(1)[[\"Name\", \"Position\", \"Mins Played\", \"playerRatings\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting feature importance from random forest\n",
    "df_feature_importance = pd.DataFrame(rf.feature_importances_, index=df2.iloc[:,15:-2].columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "   .nlargest(4)\n",
    "   .plot(kind='barh')) \n",
    "#e6b32d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('blue')\n",
    "fig.patch.set_alpha(0.6)\n",
    "\n",
    "feat_imp_data = sorted(list(zip(X_train.columns, rf.feature_importances_)), key=lambda datum: datum[1], reverse=False)[0:10]\n",
    "\n",
    "# Unzip the values and labels\n",
    "widths = [x[1] for x in feat_imp_data]\n",
    "yticks = [x[0] for x in feat_imp_data]\n",
    "\n",
    "n_features = int(X_train.shape[1])\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.patch.set_facecolor('orange')\n",
    "ax.patch.set_alpha(1.0)\n",
    "\n",
    "plt.barh(range(n_features),widths, align='center')\n",
    "plt.yticks(np.arange(n_features), X_train.columns) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(X_all.values)\n",
    "# df = pd.DataFrame(x_scaled, columns = X_all.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b =X_train.columns, df2.columns\n",
    "(a | b).difference(a & b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tactical sub in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs_live90[Player_Aggs_live90.teamId==1612].matchId.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### univariate regression\n",
    "##### Identify opposition weakness in a match\n",
    "##### Identify optimal player for tactical sub to replace our weak player and exploit their weakness\n",
    "##### Identify formation that gives opposition toughest time (label formations below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify our weakest player\n",
    "df2[(df2.matchId==2499773) & (df2.teamId==1612) &(df2.Position!=\"GKP\") &(df2.playerRatings!=0)].sort_values(\"playerRatings\", ascending=False).iloc[-1:,:]\n",
    "\n",
    "# identify opposition weakness in style and tactics\n",
    "\n",
    "\n",
    "# replace with most similar player or exploitative player\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(['matchId', 'teamId', \"result\"]).sum().reset_index().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte team performance ratings \n",
    "# df2['teamRatings'] = df2['playerRatings'].multiply(df2['gameTime (min)'])\n",
    "# team_perf = df2.groupby(['matchId', 'teamId']).sum().reset_index()\n",
    "# team_perf.drop([\"Result\",\"playerRatings\",\"playerId\", 'weight', 'height', 'xStart', 'yStart', 'homeTeamId', 'awayTeamId', 'gameTime (min)' ], axis = 1, inplace = True)\n",
    "# pd.merge(team_perf, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(x=\"Result\", y=\"teamRatings\", data=team_perf);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=10,axis='columns',replace=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WEAKNESSES (when they don't win)\n",
    "X_all = df[(df.teamId ==1612) &(df.result!=1) ]\n",
    "y_all = df[(df.teamId ==1612) &(df.result!=1)].iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.iloc[:,2:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, random_state=123)\n",
    "rf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame(rf.feature_importances_, index=df.iloc[:,2:-1].columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "df_feature_importance[0:10].plot(kind='bar');\n",
    "#fig.savefig('temp.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player_Aggs3 = Player_Aggs_live50[Player_Aggs_live50.Position!=\"GKP\"]\n",
    "# Player_Aggs3 = Player_Aggs3.loc[:, ~Player_Aggs3.columns.isin([\"xStart\",\"height\",\"homeAway\",\"yStart\", \"weight\", \"name\",\"Result\", 'matchId', 'homeTeamId', 'awayTeamId'])]\n",
    "\n",
    "# Player_Aggs3 = Player_Aggs3.groupby(['playerId' ,'teamId',]).sum().reset_index()\n",
    "\n",
    "# PV = Player_Aggs3.playerId\n",
    "# TV = Player_Aggs3.teamId\n",
    "\n",
    "# Player_Aggs3 = Player_Aggs3.iloc[:,2:].div(Player_Aggs3[\"gameTime (min)\"], axis=0) *90\n",
    "# Player_Aggs3 = pd.concat([PV, TV, Player_Aggs3], axis =1)\n",
    "\n",
    "# # Player_Aggs3  = pd.merge(Player_Aggs2[[\"playerId\",\"teamId\"]], Player_Aggs3, how = 'left', on= 'playerId')\n",
    "# # Player_Aggs3 = Player_Aggs3.drop_duplicates()\n",
    "\n",
    "# Player_Aggs3.drop([\"gameTime (min)\"], inplace = True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix diabates last name for visual\n",
    "test[test.teamId==1610].iloc[-7:-6,0:1] = \"F.Diabate\"\n",
    "\n",
    "# test.iloc[3:4,0:1] =  \"M.Hamsik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = test[(test.teamId==1639) & (test.Position!=\"GKP\")].iloc[:,:-2]\n",
    "df3 = df3.fillna(0)\n",
    "# df = Player_Aggs3.loc[:, ~Player_Aggs3.columns.isin([\"homeAway\",\"shortName\", \"name\",\"Result\", 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\n",
    "# df = df[df.teamId==1609]\n",
    "df3.drop(['teamId'], axis=1, inplace=True)\n",
    "df3 = df3.replace([np.inf, -np.inf], np.nan).fillna(mean)\n",
    "\n",
    "df_y  = pd.merge(df3['playerId'], Players[[\"shortName\", \"playerId\", \"teamId\"]], how = 'left', on='playerId')[[\"shortName\"]]\n",
    "df_y = df_y.fillna(\"none\")\n",
    "y = df_y.values\n",
    "X  = df3.iloc[:,11:].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, stratify=y)\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(X_train, y_train)\n",
    "# print(knn.score(X_test, y_test)) # prints 0.87 - i.e. 87% accurate\n",
    "# walcott = df[df.playerId==7879].drop('playerId', axis=1).values\n",
    "# salah = df[df.playerId==120353].drop('playerId', axis=1).values\n",
    "# print(knn.predict(walcott)) # prints ['midfield']\n",
    "# print(knn.predict(salah))   # prints ['defence']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams[Teams.name.str.contains(\"Wolves\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "ax = plt.figure(figsize=(12, 5))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(X, method='ward'),labels=y, leaf_rotation=0, orientation=\"left\")\n",
    "\n",
    "\n",
    "#ax = df_feature_importance[0:10].plot(kind='bar', color=\"#F0BE33\")\n",
    "\n",
    "\n",
    "# ax.patch.set_facecolor('#241C24')\n",
    "# plt.y_ticks( color = \"white\")\n",
    "#ax.tick_params(axis='x', colors='white',size =14 )\n",
    "#.tick_params(axis='y', colors='white', size=14)\n",
    "#plt.ylabel(\"Feature Importance\", color = \"white\")\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(15, 7))  # set size\n",
    "#         ax = dendrogram(linkage_matrix, **kwargs)\n",
    "#         plt.tick_params(axis='x', bottom='off', top='off', labelbottom='off')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                    counts]).astype(float)\n",
    "    print(len(counts))\n",
    "    # Plot the corresponding dendrogram\n",
    "    shc.dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "\n",
    "model = model.fit(X)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode='level', p=8)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs3[Player_Aggs3.playerId==7879] # walcott\n",
    "Player_Aggs3[Player_Aggs3.playerId==120353] # salah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Own Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamTest.loc[:, ~teamTest.columns.isin([\"name\",\"Result\",'teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events_England.drop[(\"subEventId\",), ]\n",
    "\n",
    "\n",
    "tentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# while datetime.datetime.now().hour < 13:\n",
    "#     x = 1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig.set_size_inches(14,4)\n",
    "# plt.subplot(121)\n",
    "# sns.kdeplot(Events_England[\"xStart\"], Events_England['yStart'], shade = True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Successful Vertical Yards Now Merge\n",
    "\n",
    "# df = Events_England.loc[Events_England.Result == \"Success\" ].groupby(['matchId','playerId'])['attackMetres'].sum().reset_index()\n",
    "# df2 = Events_England.loc[Events_England.Result == \"Failure\" ].groupby(['matchId','playerId'])['attackMetres'].sum().reset_index()\n",
    "\n",
    "# with names, positions and clubs for reference\n",
    "#df = pd.merge(Events_England.loc[Events_England.Result == \"Success\" ].groupby(['matchId','playerId'])['attackYards'].sum().reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on = 'playerId').sort_values(by ='attackYards', ascending = False)\n",
    "#df2 = pd.merge(Events_England.loc[Events_England.Result == \"Failure\" ].groupby(['matchId','playerId'])['attackYards'].sum().reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on = 'playerId').sort_values(by ='attackYards', ascending = False)\n",
    "\n",
    "# .sort_values(by ='attackYards', ascending = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes of brute sum of attacking yard attempts without success or failure measures\n",
    "\n",
    "#df  = pd.merge(Events_England.groupby(['matchId','playerId'])['attackYards'].agg(['sum']).reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on ='playerId').sort_values(by ='sum', ascending = False).rename(columns={'sum':'attackYards'})\n",
    "# df = Events_England.groupby(['matchId','playerId'])['attackYards'].agg(['sum']).reset_index().sort_values(by ='sum', ascending = False).rename(columns={'sum':'attackYards'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Player_Aggs = pd.merge(Player_Aggs, Matches[['matchId', \"Result\"]], how = 'left', on = 'matchId' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Live match testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Team Aggregates and Clustering Tactics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = ['playerId',\n",
    "'weight','height','xStart','yStart','homeTeamId','awayTeamId','gameTime (min)','FKCrossAccuracy','penaltiesConversion',\n",
    "'low_left_save_efficiency','mid_left_save_efficiency','high_left_save_efficiency','low_center_save_efficiency',\n",
    "'mid_center_save_efficiency','high_center_save_efficiency','low_right_save_efficiency','mid_right_save_efficiency',\n",
    "'high_right_save_efficiency','shotAccuracy','shortPassAccuracy','longPassAccuracy','shortLongPassRatio',\n",
    "'Result']\n",
    "\n",
    "dropcols_live = dropcols[0:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team_Aggs_Matches = Player_Aggs.groupby(['matchId', 'teamId' ]).sum().reset_index()\n",
    "Team_Aggs_Matches.drop(columns = dropcols, inplace=True, axis=1)\n",
    "Team_Aggs_Matches = pd.merge(Team_Aggs_Matches, Matches[['matchId', \"Country\"]], on='matchId', how = 'left')\n",
    "Teams['Country'] = [row['name'] for row in Teams.area]\n",
    "Team_Aggs = Team_Aggs_Matches.groupby(['teamId']).sum().reset_index()\n",
    "Team_Aggs.drop(columns = 'matchId', inplace=True, axis=1)\n",
    "Team_Aggs = pd.merge(Team_Aggs, Teams[['teamId', 'Country']], how = 'left', on = 'teamId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team_Aggs_Matches_live = Player_Aggs_live.groupby(['matchId', 'teamId' ]).sum().reset_index()\n",
    "Team_Aggs_Matches_live.drop(columns = dropcols_live, inplace=True, axis=1)\n",
    "Team_Aggs_Matches_live = pd.merge(Team_Aggs_Matches_live, Matches[['matchId', \"Country\"]], on='matchId', how = 'left')\n",
    "Teams['Country'] = [row['name'] for row in Teams.area]\n",
    "Team_Aggs_live = Team_Aggs_Matches_live.groupby(['teamId']).sum().reset_index()\n",
    "Team_Aggs_live.drop(columns = 'matchId', inplace=True, axis=1)\n",
    "Team_Aggs_live = pd.merge(Team_Aggs_live, Teams[['teamId', 'Country']], how = 'left', on = 'teamId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Matches_df(Team_Aggs_Matches, Team_Aggs)\n",
    "result_live = Matches_df(Team_Aggs_Matches_live, Team_Aggs_live)\n",
    "y_all = result[\"Result\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_live = result_live.loc[:, ~result_live.columns.isin([\"awayCounterAttackGoal\", \n",
    "                                                           \"Result\",'teamId', 'matchId', 'homeTeamId', \n",
    "                                                           'awayTeamId', 'homeGoal_Value','awayGoal_Value', \n",
    "                                                           'awayCornerAssists', 'awayPenaltyNotScored', 'homeCornerAssists'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = result.loc[:, ~result.columns.isin(['teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'awayGoal_Value','homegoalsAllowed', 'awaygoalsAllowed'\n",
    "                                           ,'homeGoal_low_left', 'homeGoal_mid_left', 'awayGoal_mid_right',\n",
    "                                           'homeGoal_Value', 'homeCrossAssists', 'homeCornerAssists',\n",
    "                                           'homeGoal_low_center', 'homeTotalAssists','homeRightFootGoal', 'awayRightFootGoal'\n",
    "                                           ,'homeRightFootGoal', 'awayRightFootGoal',\n",
    "       'homeLeftFootGoal', 'awayLeftFootGoal', 'homeTotalAssists',\n",
    "       'awayTotalAssists',\"Result\", 'awayGoal_low_left', 'awayGoal_low_center',\n",
    "       'homeGoal_low_right', 'awayGoal_low_right','homeHeader/Body_Goal', 'awayHeader/Body_Goal','awayCrossAssists',\n",
    "                                           'awayCrossAssists','awayInterceptionGoal',\n",
    " 'homeInterceptionGoal','awayOwnGoals','homeFKCrossAssists', 'homeGoal_high_left','awayFKCrossAssists',\n",
    " 'homeOwnGoals','homeGoal_high_right','awayGoal_high_center',\n",
    " 'awayGoal_high_left','awayInterceptionGoal','homeInterceptionGoal','awayOwnGoals','awayPenaltyNotScored',\n",
    " 'homeFKCrossAssists','homeGoal_high_left','awayFKCrossAssists',\n",
    "'awayGoal_mid_left', 'homeGoal_mid_right','homeGoal_mid_center','awayGoal_high_right','awayGoal_mid_center',\n",
    " 'homeGoal_high_center','awayCornerAssists','homeOwnGoals', 'homeGoal_high_right','awayGoal_high_center'                                      \n",
    " 'awayGoal_high_left', 'homeCounterAttackGoal', 'awayCounterAttackGoal'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_live = X_all_live.replace([np.inf, -np.inf], np.nan)\n",
    "X_all_live = X_all_live.fillna(X_all_live.mean())\n",
    "X_train_live, X_test_live, y_train_live, y_test_live = train_test_split(X_all_live, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Extracting features of team playing style using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [200,400,500, 700,1000,2000]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset AKA live match trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.replace([np.inf, -np.inf], np.nan)\n",
    "X_all = X_all.fillna(X_all.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 1000, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [-1,0,1]\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, labels = labels))\n",
    "print('accuracy score: {0:.4f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(clf.feature_importances_.argsort()[0:25])\n",
    "col = list(X_train.columns[idx])\n",
    "# modelname.feature_importance_\n",
    "y = clf.feature_importances_[0:25]\n",
    "#plot\n",
    "fig, ax = plt.subplots() \n",
    "width = 0.4 # the width of the bars \n",
    "ind = np.arange(len(y)) # the x locations for the groups\n",
    "ax.barh(ind, y, width, color='green')\n",
    "ax.set_yticks(ind+width/10)\n",
    "ax.set_yticklabels(col, minor=False)\n",
    "plt.title('Feature importance in RandomForest Classifier')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.ylabel('feature') \n",
    "plt.figure(figsize=(5,5))\n",
    "fig.set_size_inches(6.5, 4.5, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Result'], colnames=['Predicted Result']))\n",
    "class_name = list(set(y_test))\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# estimator_nonlimited = clf.estimators_[5]\n",
    "# fn = list(X_train.columns)\n",
    "# # from sklearn.tree import export_graphviz\n",
    "# # export_graphviz(estimator_limited, out_file='tree_limited.dot', feature_names = iris.feature_names,\n",
    "# #                 class_names = iris.target_names,\n",
    "# #                 rounded = True, proportion = False, precision = 2, filled = True)\n",
    "\n",
    "# export_graphviz(estimator_nonlimited, out_file='tree_nonlimited.dot', feature_names = fn,\n",
    "#                 class_names = [\"W\", \"L\", 'D'],\n",
    "#                 rounded = True, proportion = False, precision = 2, filled = True)\n",
    "\n",
    "\n",
    "# import pydot\n",
    "\n",
    "# (graph,) = pydot.graph_from_dot_file('tree_nonlimited.dot')\n",
    "# graph.write_png('tree_nonlimited.png')\n",
    "# graph.draw('tree_nonlimited.png')\n",
    "\n",
    "\n",
    "# # !dot -Tpng tree_limited.dot -o tree_nonlimited.png -Gdpi=600\n",
    "# # from IPython.display import Image\n",
    "# # Image(filename = 'tree_nonlimited.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import *\n",
    "import dtreeviz\n",
    "from IPython.core.display import display, HTML\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "fn = list(X_train.columns)\n",
    "cn = [-1,0,1]\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier(random_state=0)\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "viz = dtreeviz(dtree,\n",
    "               X_train,\n",
    "               y_train,\n",
    "               feature_names=fn, \n",
    "               class_names=cn,\n",
    "               fancy=False)\n",
    "\n",
    "viz.view()\n",
    "\n",
    "# display(HTML(viz.svg()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC AUC for each class\n",
    "n_classes = 3\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "all_y_test_i = np.array([])\n",
    "all_y_predict_proba = np.array([])\n",
    "for i in [-1,0,1]:\n",
    "    y_test_i = list(map(lambda x: 1 if x == i else 0, list(y_test)))\n",
    "    if len(all_y_test_i) >0:\n",
    "        all_y_test_i = np.concatenate([all_y_test_i, y_test_i])\n",
    "    else:\n",
    "        all_y_test_i = y_test_i\n",
    "    all_y_predict_proba = np.concatenate([all_y_predict_proba, y_predict_proba[:, i]])\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_i, y_predict_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"average\"], tpr[\"average\"], _ = roc_curve(all_y_test_i, all_y_predict_proba)\n",
    "roc_auc[\"average\"] = auc(fpr[\"average\"], tpr[\"average\"])\n",
    "\n",
    "\n",
    "# Plot average ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"average\"], tpr[\"average\"],\n",
    "         label='Average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"average\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "# Plot each individual ROC curve\n",
    "for i in [-1,0,1]:\n",
    "    plt.plot(fpr[i], tpr[i], lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "# ns_probs = [0 for _ in range(len(y_test))]\n",
    "# ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "# plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "\n",
    "# #Now calculate the AUC for each class separately\n",
    "\n",
    "y_predict_proba = clf.predict_proba(X_test)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "all_y_test_i = np.array([])\n",
    "all_y_predict_proba = np.array([])\n",
    "\n",
    "WDL = [\"Draw\",\"Home Win\", \"Home Loss\"]\n",
    "\n",
    "for pp in [-1,0,1]:\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,  \n",
    "                     clf.predict_proba(X_test)[:,pp], pos_label = pp)\n",
    "    plt.plot(fpr, tpr,  marker='.', label= WDL[pp])\n",
    "    auroc = round(metrics.auc(fpr, tpr),2)\n",
    "    print('RF',WDL[pp],'--AUC--->',auroc)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matches = Matches.shape[0]\n",
    "n_features = Matches.shape[1] -1\n",
    "n_homewins =  len(Matches[Matches.Result==1])\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "n_homeloss =  len(Matches[Matches.Result==-1])\n",
    "loss_rate = (float(n_homeloss) / (n_matches)) * 100\n",
    "print(\"Total number of matches: {}\".format(n_matches))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print('Number of matches won by home side: {}'.format(n_homewins))\n",
    "print('Win rate of home team {:2f}%'.format(win_rate))\n",
    "print('Loss rate of home team {:2f}%'.format(loss_rate))\n",
    "print(collections.Counter(Matches.Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = [\n",
    " 'playerId',\n",
    " 'weight',\n",
    " 'height',\n",
    " 'xStart',\n",
    " 'yStart',\n",
    " 'homeTeamId',\n",
    " 'awayTeamId',\n",
    " 'gameTime (min)',\n",
    "#  'AccurateAttackMetres',\n",
    "#  'InaccurateAttackMetres',\n",
    "#  'Goal_Value',\n",
    "#  'SimulationFouls',\n",
    "#  'FoulsCommited',\n",
    "#  'Clearances',\n",
    "#  'AccLaunchMetres',\n",
    "#  'InaccLaunchMetres',\n",
    "#  'FKKeyCross',\n",
    "#  'FKCrossAssists',\n",
    " 'FKCrossAccuracy',\n",
    " 'penaltiesConversion',\n",
    "#  'dangerousOpponentHalfRecoveries',\n",
    "#  'dangerousOwnHalfBallLost',\n",
    "#  'dangerousDefDuelsLost',\n",
    " 'low_left_save_efficiency',\n",
    " 'mid_left_save_efficiency',\n",
    " 'high_left_save_efficiency',\n",
    " 'low_center_save_efficiency',\n",
    " 'mid_center_save_efficiency',\n",
    " 'high_center_save_efficiency',\n",
    " 'low_right_save_efficiency',\n",
    " 'mid_right_save_efficiency',\n",
    " 'high_right_save_efficiency',\n",
    "#  'goalsAllowed',\n",
    "#  'GkSaves',\n",
    "#  'AccurateHandPass',\n",
    "#  'InaccurateHandPass',\n",
    "#  'GKLeavingLineInstance',\n",
    "#  'SuccessfulAccels',\n",
    "#  'FailedAccels',\n",
    "#  'CumAccelerationDist',\n",
    "#  'AccelsDistIntoFinal3rd',\n",
    "#  'AccelsDistWithinFinal3rd',\n",
    "#  'CrossAssists',\n",
    "#  'RightFootCross',\n",
    "#  'LeftFootCross',\n",
    "#  'CrossKeyPass',\n",
    "#  'AccCrosses',\n",
    "#  'InaccCrosses',\n",
    "#  'AccCrossesIntoBox',\n",
    "#  'InaccCrossesIntoBox',\n",
    "#  'SlidingTacklesWon',\n",
    "#  'SlidingTacklesLost',\n",
    "#  'GroundDefDuelsWon',\n",
    "#  'GroundDefDuelsLost',\n",
    "#  'DefensiveAnticipations',\n",
    "#  'GroundLooseBallsWon',\n",
    "#  'GroundLooseBallsLost',\n",
    "#  'GroundAttackDuelsWon',\n",
    "#  'GroundAttackDuelsLost',\n",
    "#  'OffensiveTouchesBox',\n",
    "#  'Goal_low_left',\n",
    "#  'Goal_mid_left',\n",
    "#  'Goal_high_left',\n",
    "#  'Goal_low_center',\n",
    "#  'Goal_mid_center',\n",
    "#  'Goal_high_center',\n",
    "#  'Goal_low_right',\n",
    "#  'Goal_mid_right',\n",
    "#  'Goal_high_right',\n",
    " 'shotAccuracy',\n",
    "#  'ShotsOnTarget',\n",
    "#  'ShotsOffTarget',\n",
    "#  'ShotOpportunities',\n",
    "#  'FreeKickShotAcc',\n",
    "#  'FreeKickShotInacc',\n",
    "#  'PenaltyNotScored',\n",
    "#  'Header/Body_Goal',\n",
    "#  'RightFootGoal',\n",
    "#  'LeftFootGoal',\n",
    "#  'CounterAttackGoal',\n",
    "#  'InterceptionGoal',\n",
    "#  'OwnGoals',\n",
    "#  'AerialDuelsWon',\n",
    "#  'AerialDuelsLost',\n",
    " 'shortPassAccuracy',\n",
    " 'longPassAccuracy',\n",
    " 'shortLongPassRatio',\n",
    "#  'InaccPassesWithinFinalThird',\n",
    "#  'AccPassesWithinFinalThird',\n",
    "#  'AccPassesIntoFinalThird',\n",
    "#  'InaccPassesIntoFinalThird',\n",
    "#  'AccThroughsIntoFinalThird',\n",
    "#  'InaccurateSmartPasses',\n",
    "#  'AccurateSmartPasses',\n",
    "#  'InaccurateThroughPasses',\n",
    "#  'AccurateThroughPasses',\n",
    "#  'AccurateKeyPasses',\n",
    "#  'InaccurateKeyPasses',\n",
    "#  'TotalAssists',\n",
    "#  'CounterAttackInvolvements',\n",
    "#  'PassLostDangerous',\n",
    "#  'CounterAttackIntercept',\n",
    "#  'SuccessfulInterceptions',\n",
    "#  'InaccurateForwardPasses',\n",
    "#  'AccurateForwardPasses',\n",
    "#  'CornerAssists',\n",
    "#  'CornerOpportunitiesCreated',\n",
    "#  'SuccessfulCorners',\n",
    "#  'FailedCorners',\n",
    " 'Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeans for detecting and visualizing team formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# live adaptable formation\n",
    "def team_formation(event_df, teamId, matchId):\n",
    "    event_df = event_df[(event_df.teamId==teamId)&(event_df.matchId==matchId)]\n",
    "    maxtime = event_df.eventSec.max()\n",
    "    if maxtime > 1200:\n",
    "        mintime = maxtime - 1200 # last 20mins of match data for formation revelation\n",
    "    else:\n",
    "        mintime = 0\n",
    "    x1 = np.array(event_df[(event_df.eventSec > mintime)].xStart) \n",
    "    x2 = np.array(event_df[(event_df.eventSec > mintime)].yStart)\n",
    "    X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n",
    "    return x1, x2, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data \n",
    "x1, x2, X = team_formation(Events_England, 1609, 2499719)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=11, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 7)\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "\n",
    "# pitch borderline and centrer line\n",
    "plt.plot([0,0],[0,100], color=\"white\")\n",
    "plt.plot([0,100],[100,100], color=\"white\")\n",
    "plt.plot([100,100],[100,0], color=\"white\")\n",
    "plt.plot([100,0],[0,0], color=\"white\")\n",
    "plt.plot([50,50],[0,100], color=\"white\") # center line\n",
    "\n",
    "# left penalty area\n",
    "plt.plot([16.5,16.5],[75,25],color=\"white\")\n",
    "plt.plot([0,16.5],[75,75],color=\"white\")\n",
    "plt.plot([16.5,0],[25,25],color=\"white\")\n",
    "\n",
    "#Right Penalty Area\n",
    "plt.plot([83.5,100],[75,75],color=\"white\")\n",
    "plt.plot([83.5,83.5],[75,25],color=\"white\")\n",
    "plt.plot([83.5,100],[25,25],color=\"white\")\n",
    "\n",
    "#Left 6-yard Box\n",
    "plt.plot([0,5.5],[64,64],color=\"white\")\n",
    "plt.plot([5.5,5.5],[64,36],color=\"white\")\n",
    "plt.plot([5.5,0.5],[36,36],color=\"white\")\n",
    "\n",
    "#Right 6-yard Box\n",
    "plt.plot([100,94.5],[64,64],color=\"white\")\n",
    "plt.plot([94.5,94.5],[64,36],color=\"white\")\n",
    "plt.plot([94.5,100],[36,36],color=\"white\")\n",
    "\n",
    "#Prepare Circles\n",
    "centreCircle = plt.Circle((50,50),9.15,color=\"white\",fill=False)\n",
    "centreSpot = plt.Circle((50,50),0.6,color=\"white\")\n",
    "leftPenSpot = plt.Circle((11,50),0.6,color=\"white\")\n",
    "rightPenSpot = plt.Circle((89,50),0.6,color=\"white\")\n",
    "\n",
    "# zones\n",
    "plt.plot([100,0],[25,25],color=\"white\", linestyle='--') \n",
    "plt.plot([100,0],[75,75],color=\"white\", linestyle='--') \n",
    "plt.plot([100,0],[25,25],color=\"white\", linestyle='--') \n",
    "plt.plot([33,33],[75,25],color=\"white\", linestyle='--')\n",
    "plt.plot([67,67],[75,25],color=\"white\", linestyle='--')\n",
    "plt.plot([33,33],[100,75],color=\"white\", linestyle='--')\n",
    "plt.plot([16.5,16.5],[100,75],color=\"white\", linestyle='--')\n",
    "plt.plot([67,67],[100,75],color=\"white\", linestyle='--')\n",
    "plt.plot([83.5,83.5],[100,75],color=\"white\", linestyle='--')\n",
    "plt.plot([33,33],[0,25],color=\"white\", linestyle='--')\n",
    "plt.plot([16.5,16.5],[0,25],color=\"white\", linestyle='--')\n",
    "plt.plot([67,67],[0,25],color=\"white\", linestyle='--')\n",
    "plt.plot([83.5,83.5],[0,25],color=\"white\", linestyle='--')\n",
    "plt.plot([16.5,83.5],[50,50],color=\"white\", linestyle='--')\n",
    "plt.plot([33,33],[0,25],color=\"white\", linestyle='--')\n",
    "plt.plot([0,16.5],[64,64],color=\"white\", linestyle='--')\n",
    "plt.plot([0,16.5],[36,36],color=\"white\", linestyle='--')\n",
    "plt.plot([83.5,100],[64,64],color=\"white\", linestyle='--')\n",
    "plt.plot([83.5,100],[36,36],color=\"white\", linestyle='--')\n",
    "\n",
    "# Fill with green\n",
    "green = patches.Rectangle((0, 0), 100, 100, linewidth=0.1,\n",
    "                             edgecolor='r', facecolor='darkgreen', zorder=0, alpha = 0.8)\n",
    "ax.add_patch(green)\n",
    "\n",
    "#Draw Circles\n",
    "ax.add_patch(centreCircle)\n",
    "ax.add_patch(centreSpot)\n",
    "ax.add_patch(leftPenSpot)\n",
    "ax.add_patch(rightPenSpot)\n",
    "\n",
    "#Prepare Arcs\n",
    "leftArc = Arc((11,50),height=18.3,width=18.3,angle=0,theta1=310,theta2=50,color=\"white\")\n",
    "rightArc = Arc((89,50),height=18.3,width=18.3,angle=0,theta1=130,theta2=230,color=\"white\")\n",
    "\n",
    "#Draw Arcs\n",
    "ax.add_patch(leftArc)\n",
    "ax.add_patch(rightArc)\n",
    "\n",
    "# #Tidy Axes\n",
    "# plt.axis('off')\n",
    "\n",
    "# #K-Means Live formation\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=30, cmap='viridis')\n",
    "# plt.scatter(centers[:, 0], centers[:, 1], c='red', s=600, alpha=0.5)\n",
    "\n",
    "#Heat Map of Player and Action Type\n",
    "team = Events_Spain[(Events_Spain.playerId == 3359) & (Events_Spain.matchId == 2565907)  & (Events_Spain.subEventName==\"Shot\") ]\n",
    "sns.kdeplot(team[\"xStart\"],team[\"yStart\"], shade=True)\n",
    "# team2 = Events_Spain[(Events_Spain.playerId == 3322) & (Events_Spain.matchId == 2565907)  & (Events_Spain.subEventName==\"Shot\") ]\n",
    "# sns.kdeplot(team2[\"xStart\"],team2[\"yStart\"], shade=True, color=\"Red\")\n",
    "\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=11, cmap='viridis')\n",
    "# centers = kmeans.cluster_centers_\n",
    "# plt.scatter(centers[:, 0], centers[:, 1], c='red', s=400, alpha=0.5)\n",
    "\n",
    "plt.ylim(100, 0)\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data \n",
    "x1 = np.array(Player_Aggs[Player_Aggs['gameTime (min)']>45].xStart) \n",
    "x2 = np.array(Player_Aggs[Player_Aggs['gameTime (min)']>45].yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = [] \n",
    "inertias = [] \n",
    "mapping1 = {} \n",
    "mapping2 = {} \n",
    "K = range(1,15) \n",
    "  \n",
    "for k in K: \n",
    "    #Building and fitting the model \n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X) \n",
    "    kmeanModel.fit(X)     \n",
    "      \n",
    "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n",
    "                      'euclidean'),axis=1)) / X.shape[0]) \n",
    "    inertias.append(kmeanModel.inertia_) \n",
    "  \n",
    "    mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n",
    "                 'euclidean'),axis=1)) / X.shape[0] \n",
    "    mapping2[k] = kmeanModel.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, inertias, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Inertia') \n",
    "plt.title('The Elbow Method using Inertia') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, distortions, 'bx-') \n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Distortion') \n",
    "plt.title('The Elbow Method using Distortion') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what four pitch area location clusters look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Traditional 11 pitch positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liverpool formation last twenty minutes versus Man Utd at Anfield\n",
    "np.array(Events_England[(Events_England.teamId == 1612) (Events_England.matchId==2499793) & (Events_England.eventSec <3700) * (Events_England.eventSec > 2400)].xStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data for Liverpool live formation at 60mins\n",
    "\n",
    "x1 = np.array(Events_England[(Events_England.teamId == 1612) &(Events_England.matchId==2499793) & (Events_England.eventSec <3700) & (Events_England.eventSec > 1900)].xStart)\n",
    "x2 = np.array(Events_England[(Events_England.teamId == 1612) &(Events_England.matchId==2499793) & (Events_England.eventSec <3700) & (Events_England.eventSec > 1900)].yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=800, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=22)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Two Teams in a head to head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams[Teams[\"name\"].str.contains('Barcelona')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data\n",
    "manUtdBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\n",
    "manUtdGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\n",
    "liverpoolGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1612) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\n",
    "liverpoolBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1612) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\n",
    "barcelonaBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\n",
    "barcelonaGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\n",
    "\n",
    "\n",
    "x1 = np.array(manUtdBad.xStart) \n",
    "x2 = np.array(manUtdBad.yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers2 = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(manUtdGood.xStart) \n",
    "x2 = np.array(manUtdGood.yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "# plt.scatter(centers2[:, 0], centers2[:, 1], c='red', s=200, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manUtd = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611)]\n",
    "barca = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Man Utd\n",
    "x1 = np.array(manUtd.xStart) \n",
    "x2 = np.array(manUtd.yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n",
    "\n",
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Barcelona\n",
    "x1 = np.array(barca.xStart) \n",
    "x2 = np.array(barca.yStart)\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n",
    "\n",
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events_England = pd.read_csv('eventsEvents_England_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player_Aggs_live = pd.read_csv('eventsPlayer_Aggs_live.csv')\n",
    "# Player_Aggs = pd.read_csv('eventsPlayer_Aggs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player_Aggs_live.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Matches_df_fDNN(TAM, TA):\n",
    "    \n",
    "#     df2 = TAM.groupby('matchId').agg(list).reset_index()\n",
    "#     df2.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)\n",
    "#     df3 = pd.DataFrame(None, columns = list(TA.columns))\n",
    "\n",
    "#     for index, col in enumerate(list(TAM.columns)):\n",
    "#         df3[col] = df2.iloc[:,index]\n",
    "\n",
    "#     df4 = pd.concat([df3, pd.DataFrame(df3['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n",
    "#     result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n",
    "#     #df4.drop([\"Country\"], axis=1, inplace=True)\n",
    "\n",
    "#     for var in list(result.columns)[2:-5]:\n",
    "#         result = pd.concat([result, pd.DataFrame(df3[var].to_list(), columns=[\"1_\" + var, \"2_\" + var])], axis=1, sort = False)\n",
    "\n",
    "#         # Correctly apply allocate home and away aggregate statistics to correct teams\n",
    "#         result['home'+var] = (\n",
    "#             np.select(\n",
    "#                 condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n",
    "#                 choicelist=[result[\"1_\" + var], result[\"2_\" + var]]))\n",
    "\n",
    "#         result['away'+var] = (\n",
    "#             np.select(\n",
    "#                 condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n",
    "#                 choicelist=[result[\"1_\" + var], result[\"2_\" + var]]))\n",
    "\n",
    "#         # # drop useless columns that have been replaced\n",
    "#         result.drop([ var, \"1_\" + var, \"2_\" + var], inplace = True, axis = 1 )\n",
    "\n",
    "#     # # drop useless columns that have been replaced\n",
    "#     result.drop(['teamId',\"team1\", \"team2\"], inplace = True, axis = 1 )\n",
    "#     result = pd.merge(result, Matches[['matchId', \"Result\"]], on='matchId', how = 'left')\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Matches_df(TAM, TA):\n",
    "    \n",
    "#     df2 = TAM.groupby('matchId').agg(list).reset_index()\n",
    "#     df2.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)\n",
    "#     df3 = pd.DataFrame(None, columns = list(TA.columns))\n",
    "\n",
    "#     for index, col in enumerate(list(TAM.columns)):\n",
    "#         df3[col] = df2.iloc[:,index]\n",
    "\n",
    "#     df4 = pd.concat([df3, pd.DataFrame(df3['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n",
    "#     result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n",
    "#     #df4.drop([\"Country\"], axis=1, inplace=True)\n",
    "\n",
    "#     for var in list(result.columns)[1:-6]:\n",
    "#         result = pd.concat([result, pd.DataFrame(df3[var].to_list(), columns=[var+\"1\",var+\"2\"])], axis=1, sort = False)\n",
    "\n",
    "#         # Correctly apply allocate home and away aggregate statistics to correct teams\n",
    "#         result['home'+var] = (\n",
    "#             np.select(\n",
    "#                 condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n",
    "#                 choicelist=[result[var+\"1\"], result[var+\"2\"]]))\n",
    "\n",
    "#         result['away'+var] = (\n",
    "#             np.select(\n",
    "#                 condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n",
    "#                 choicelist=[result[var+\"1\"], result[var+\"2\"]]))\n",
    "\n",
    "#         # # drop useless columns that have been replaced\n",
    "#         result.drop([ var, var+\"1\", var+\"2\"], inplace = True, axis = 1 )\n",
    "\n",
    "#     # # drop useless columns that have been replaced\n",
    "#     result.drop(['teamId',\"team1\", \"team2\"], inplace = True, axis = 1 )\n",
    "#     result = pd.merge(result, Matches[['matchId', \"Result\"]], on='matchId', how = 'left')\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### ORIGINAL\n",
    "\n",
    "# dropcols = ['playerId',\n",
    "# 'weight','height','xStart','yStart','homeTeamId','awayTeamId','gameTime (min)','penaltiesConversion',\n",
    "# 'low_left_save_efficiency','mid_left_save_efficiency','high_left_save_efficiency','low_center_save_efficiency',\n",
    "# 'mid_center_save_efficiency','high_center_save_efficiency','low_right_save_efficiency','mid_right_save_efficiency',\n",
    "# 'high_right_save_efficiency','shotAccuracy','shortPassAccuracy','longPassAccuracy','shortLongPassRatio',\n",
    "# 'Result'][0:7]\n",
    "\n",
    "# dropcols_live =  dropcols[0:7]\n",
    "\n",
    "# Team_Aggs_Matches = Player_Aggs2.groupby(['matchId', 'teamId' ]).sum().reset_index()\n",
    "# Team_Aggs_Matches.drop(columns = dropcols, inplace=True, axis=1)\n",
    "\n",
    "# Team_Aggs = Team_Aggs_Matches.groupby(['teamId']).sum().reset_index()\n",
    "# Team_Aggs.drop(columns = ['matchId'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We performed this and found our best params which are used in the model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RANDOM FORESTS WITh GRIDSEARCH\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize results\n",
    "\n",
    "# print(\"best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(clf.feature_importances_.argsort()[0:25])\n",
    "col = list(X_train.columns[idx])\n",
    "\n",
    "# modelname.feature_importance_\n",
    "\n",
    "y = clf.feature_importances_[0:25]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots() \n",
    "width = 0.4 # the width of the bars \n",
    "ind = np.arange(len(y)) # the x locations for the groups\n",
    "ax.barh(ind, y, width, color='green')\n",
    "ax.set_yticks(ind+width/10)\n",
    "ax.set_yticklabels(col, minor=False)\n",
    "plt.title('Feature importance in RandomForest Classifier')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.ylabel('feature') \n",
    "plt.figure(figsize=(5,5))\n",
    "fig.set_size_inches(6.5, 4.5, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = Player_Aggs_live30.iloc[:,:15]\n",
    "df2 = Player_Aggs_live30.iloc[:,15:]\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan)\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df2.values)\n",
    "df2 = pd.DataFrame(x_scaled, columns = df2.columns)\n",
    "\n",
    "base_imp = imp_df(df2.columns, rf.feature_importances_)\n",
    "xxx = base_imp.transpose()\n",
    "xxx.columns = xxx.iloc[0]\n",
    "xxx = xxx.drop(xxx.index[[0]])\n",
    "xxx = xxx.reindex(sorted(xxx.columns), axis=1)\n",
    "df2 = df2.reindex(sorted(df2.columns), axis=1)\n",
    "df2 = df2.multiply(xxx.values)\n",
    "df2[negatives] = df2[negatives].multiply(-1)\n",
    "df2[\"sum\"] = df2.sum(axis=1)\n",
    "df2 = pd.concat([df1, df2], axis=1)\n",
    "df2 = pd.merge(df2, df[[\"matchId\", 'teamId', \"Result\"]], on =['matchId', \"teamId\"], how = 'left' )\n",
    "#df2 = df2.loc[:, (df2 != 0).any(axis=0)]\n",
    "df2['playerRatings']=  np.where(df2['gameTime (min)'] ==0, 0, df2['sum'])\n",
    "df2['playerRatings'] = df2['playerRatings'].multiply(94 / df2.playerRatings.max())\n",
    "df2.drop([\"sum\"], axis=1, inplace=True)\n",
    "collections.Counter(df2.sort_values(\"playerRatings\", ascending=False).iloc[0:100,:].Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import *\n",
    "import dtreeviz\n",
    "from IPython.core.display import display, HTML\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "fn = list(X_all.columns)\n",
    "cn = [-1,0,1]\n",
    "\n",
    "_ = tree.plot_tree(clf.estimators_[0], feature_names=X_all.columns, filled=True, max_depth=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
